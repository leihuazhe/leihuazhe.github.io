{"pages":[{"title":"404 Not Found：该页无法显示","text":"回主页 · 所有文章 · 留言板 可在边栏搜索框中对本站进行检索，以获取相关信息。 以下是博主喜欢的一些歌曲，可以听听，稍作休息~ .article-meta { display: none; } #container .article .article-title { padding-right: 0; } .article-header { padding: 0; padding-top: 26px; border-left: none; text-align: center; } .article-header:hover { border-left: none; } .article-title { font-size: 1.6em } .article-entry hr { margin: 0;} .article-meta, #container .article-info-post.article-info { display: none;} #container .article .article-title { padding: 0; } .article-title { font-size: 2.1em; } strong a { color: #747474; } .player { margin-left: -10px; } .sign { text-align: right; font-style: italic; } .share, #page-visit, .visit span:nth-child(2), .pic br { display: none; } .center { text-align: center; height: 2.5em; font-weight: bold; } .search2 { height: 2.2em; font-size: 1em; width: 50%; margin: auto 24%; color: #727272; opacity: .6; border: 2px solid lightgray; } .search2:hover { opacity: 1; box-shadow: 0 0 10px rgba(0, 0, 0, 0.3) }; .article-entry hr { margin: 0; } .pic { text-align: center; margin: 0; }","link":"/404.html"},{"title":"关于我","text":"个人信息 我是一名 Java 开发者,专注于后端开发,本博客将会分享我的学习所得。 联系方式 email：295482300@qq.com 关注我 GitHub 简书 博客园 优选音乐","link":"/about/backup.html"},{"title":"我想就这样牵着你的手不放","text":"开发工具类 前端在线工具 CSS速查 CSS三角生成 CSS透明效果转换 CSS3动画工具 CSS3气泡对话框生成 CSS阴影边框生成 CSS弹性布局flex JS解压缩工具 HTML转JS 正则表达式 JSON转换工具 CSS解压缩工具 图片转Base64编码 在线二维码生成 HTML转换JS字符串 W3C在线工具集 favicon图标生成 代码着色 Java学习链接 - SpringCloud - [周立的博客](http://www.itmuch.com/) - [程序员DD](http://blog.didispace.com/) - [泥瓦匠](http://www.bysocket.com/) - [一叶知秋](https://muyinchen.github.io/) - [江南一点雨](http://blog.csdn.net/u012702547) - [梁桂钊](http://blog.720ui.com/) - [KL博客](https://kailing.pub/) - [徐靖峰](https://www.cnkirito.moe/) - 设计模式 - [左潇龙](http://www.cnblogs.com/zuoxiaolong/category/509144.html) - [一叶知秋](https://muyinchen.github.io/) - Java并发 - [chenssy的博客](http://blog.csdn.net/chenssy) - [并发书单](http://www.sohu.com/a/155801182_115128?qq-pf-to=pcqq.group) - [并发编程网](http://ifeve.com/) - Auth权限控制 - [林祥](http://412887952-qq-com.iteye.com/category/356333) - [SO JSON](http://www.sojson.com/blog/165.html) - [zifangsky的个人博客](https://www.zifangsky.cn/rbac) 爱可不可以简简单单没有伤害","link":"/tools/index.html"},{"title":"所有的相遇，都是早有预谋的重逢","text":"阿里感悟 spring boot-整合CAS Client实现单点登陆验证 使用token怎么做权限控制的呢？ 设计模式总结 如何正确接收 GitHub 的消息邮件 Angular CLI 使用教程指南参考","link":"/share/index.html"},{"title":"关于我","text":"听会儿歌吧 个人信息 我是一名 Java 开发者,专注于后端开发,本博客将会分享我的学习所得。 联系方式 email：295482300@qq.com 关注我 GitHub 简书 博客园","link":"/about/index.html"}],"posts":[{"title":"Angular学习（一） Hello World","text":"Angular-Cli 的安装与使用1.node.js环境需要有npm包管理工具，由于npm是国外资源，可能种种原因导致npm安装比较慢，这里我们采用淘宝的npm镜像 1npm install cnpm -g --registry=https://registry.npm.taobao.org 然后采用cnpm安装angular-cli 1cnpm install -g @angular/cli || cnpm install -g @angular/cli@latest 安装完成之后，可以通过以下命名查看版本信息 1ng version 2.创建angular项目我们采用先创建项目，再用cpm下载模块的方式创建angular项目，这样速度比较快。 1ng new my-app --skip install 通过后面这个参数，先不安装模块 12cd my-appcnpm install 然后启动 1ng server || ng serve --host 0.0.0.0 --port 4201 ||ng serve --port 4201 访问浏览器 1localhost:4200 3.Cli常用指令1ng help 可以查看各种指令的信息API 1ng new my-app 新建一个项目 参数分类 --dry-run 只把创建环节走一遍，不会产生任何文件之类。--prefix 用Cli创建组件Component,命令如下： 1ng g component test 创建组件test 创建Service, 创建的service要在根module上进行注册, 这里用 -m来进行注册 1ng g service test -m src/app/app.module.ts 创建服务，并且在根module上注册 打包命令 1ng build 大概4M左右 1ng build -aot 预编译 压缩 2.9M 1ng build -prod 生产环境 压缩 404k 4.helloworld工程 5.工程目录说明 package.json：用来标记出本项目所需的 npm 依赖包。 tsconfig.json：定义了 TypeScript 编译器如何从项目源文件生成 JavaScript 代码。 typings.json：为那些 TypeScript 编译器无法识别的库提供了额外的定义文件。 webpack.config.js：为构建Angular应用所进行的一系列webpack配置。 karma.conf.js：Karma单元测试配置。 我们在开发的时候主要就是在src/app文件中（这个前面有提到过） src/app/app.component.ts： 这个就是处理组件业务逻辑的地方。 src/app/app.component.html： 这个就是编写组件的页面的html的地方。 src/app/app.component.css： 这个就是页面的样式编辑文件。 src/app/app.module.ts： 根模块文件，用来启动项目的文件。 src/app/app.component.spec.ts： 用于单元测试。（可选）。 具体其他的文件或者配置项在项目的根目录下的README.md中有解释。 – end –","link":"/p/e3e0b9b4.html"},{"title":"🍎 Dubbo SPI 之 Adaptive 自适应类","text":"翻看 Dubbo 的源码，不难发现，框架到处都在用 SPI 机制进行扩展。这是由于 Dubbo 框架对各种层做了很多的实现方式，然后由用户自己去选择具体的实现方式。比如 Protocol，Dubbo 提供的实现就有 dubbo，hessian，thrift，redis，inJvm 等等。这么多的实现方式，Dubbo 是如何做到动态的切换的呢？ 接口自适应与 @Adaptive 注解 Dubbo 没有采用 JDK 提供的 SPI 机制，而是自己实现了一套，增强了很多功能。具体细节可以浏览网上其他博客。 Dubbo 充分利用面向对象思想，每一个组件内引入其他组件都是以接口的形式进行依赖，动态的 inject 实现类。所以这种思想上也用到了 AOP 和 DI 的思想。我们定义一个接口 Registry，假定它的功能是将本地服务暴露到注册中心，以及从注册中心获取可用服务，属于 RPC 框架中的服务注册与发现组件。 12345678910111213@SPI(&quot;zookeeper&quot;)public interface Registry { /** * 注册服务 */ @Adaptive() String register(URL url, String content); /** * 发现服务 */ @Adaptive() String discovery(URL url, String content);} @SPI 注解标注这是一个可扩展的组件，注解内的内容后文详细介绍。 该接口定义了两个方法 register和 discovery，分别代表注册服务和发现服务。两个方法中都有 URL 参数，该类是 Dubbo 内置的类，代表了 Dubbo 整个执行过程中的上下文信息，包括各类配置信息，参数等。content 代表备注信息。 @Adaptive()注解表明这两个方法都是自适应方法，具体作用后文分析。 下面分别是两个实现类 ZookeeperRegistry 、EtcdRegistry ZookeeperRegistry123456789101112131415161718public class ZookeeperRegistry implements Registry { private Logger logger = LoggerFactory.getLogger(ZookeeperRegistry.class); @Override public String register(URL url, String content) { logger.info(&quot;服务: {} 已注册到zookeeper上，备注: {}&quot;, url.getParameter(&quot;service&quot;), content); return &quot;Zookeeper register already! &quot;; } @Override public String discovery(URL url, String content) { logger.info(&quot;zookeeper上发现服务: {} , 备注: {}&quot;, url.getParameter(&quot;service&quot;), content); return &quot;Zookeeper discovery already! &quot;; }} EtcdRegistry123456789101112131415161718public class EtcdRegistry implements Registry { private Logger logger = LoggerFactory.getLogger(ZookeeperRegistry.class); @Override public String register(URL url, String content) { logger.info(&quot;服务: {} 已注册到 Etcd 上，备注: {}&quot;, url.getParameter(&quot;service&quot;), content); return &quot;Etcd register already! &quot;; } @Override public String discovery(URL url, String content) { logger.info(&quot;Etcd 上发现服务: {} , 备注: {}&quot;, url.getParameter(&quot;service&quot;), content); return &quot;Etcd discovery already! &quot;; }} 我们可以将服务注册信息注册到老牌注册中心 zookeeper 上，或者使用新兴流行轻量级注册中心 etcd 上。 配置扩展点实现信息到 Resource 目录下在 Resource 下的 META-INF.dubbo 下新建 以 Registry 全限定名为名的文件，配置实现类信息，以 key-value 的形式。（这里要注意与 JDK 默认的 SPI 机制的区别） 文件内内容如下: 12etcd=com.maple.spi.impl.EtcdRegistryzookeeper=com.maple.spi.impl.ZookeeperRegistry 测试 Dubbo SPI 自适应类123456789101112public class Main { public static void main(String[] args) { URL url = URL.valueOf(&quot;test://localhost/test&quot;) .addParameter(&quot;service&quot;, &quot;helloService&quot;); Registry registry = ExtensionLoader.getExtensionLoader(Registry.class) .getAdaptiveExtension(); String register = registry.register(url, &quot;maple&quot;); System.out.println(register); }} 该程序首先通过 Registry 接口得到它专属的 ExtensionLoader 实例，然后调用 getAdaptiveExtension 拿到该接口的自适应类。Dubbo 会判断是否有实现类(即实现了 Registry 接口) 上有注解 @Adaptive，如果没有就会动态生成。本例子将会动态生成。 直接运行程序结果如下,程序最终选择的实现类是 ZookeeperRegistry，控制台结果如下: 1209-20 23:43:13 323 main INFO - 服务: helloService 已注册到zookeeper上，备注: mapleZookeeper register already! 上面代码我们没有看到任何实现类的信息，Dubbo SPI 机制会为动态的去调用实现类。 我们重点分析 getAdaptiveExtension 方法找到的是 Registry 的自适应类，可以理解为是 Registry 的一个 适配器和代理类。如果该适配器类不存在，Dubbo 会通过动态代理方式在运行时自动生成一个自适应类。 打开 DEBUG 日志，在控制台我们看到了 Dubbo 生成的类的源码如下： 12345678910111213141516171819202122232425package com.maple.spi;import com.alibaba.dubbo.common.extension.ExtensionLoader;public class Registry$Adaptive implements com.maple.spi.Registry { public java.lang.String register(com.alibaba.dubbo.common.URL arg0, java.lang.String arg1) { if (arg0 == null) throw new IllegalArgumentException(&quot;url == null&quot;); com.alibaba.dubbo.common.URL url = arg0; String extName = url.getParameter(&quot;registry&quot;, &quot;zookeeper&quot;); if (extName == null) throw new IllegalStateException(&quot;Fail to get extension(com.maple.spi.Registry) name from url(&quot; + url.toString() + &quot;) use keys([registry])&quot;); com.maple.spi.Registry extension = (com.maple.spi.Registry) ExtensionLoader.getExtensionLoader(com.maple.spi.Registry.class).getExtension(extName); return extension.register(arg0, arg1); } public java.lang.String discovery(com.alibaba.dubbo.common.URL arg0, java.lang.String arg1) { if (arg0 == null) throw new IllegalArgumentException(&quot;url == null&quot;); com.alibaba.dubbo.common.URL url = arg0; String extName = url.getParameter(&quot;registry&quot;, &quot;zookeeper&quot;); if (extName == null) throw new IllegalStateException(&quot;Fail to get extension(com.maple.spi.Registry) name from url(&quot; + url.toString() + &quot;) use keys([registry])&quot;); com.maple.spi.Registry extension = (com.maple.spi.Registry) ExtensionLoader.getExtensionLoader(com.maple.spi.Registry.class).getExtension(extName); return extension.discovery(arg0, arg1); }} 看代码，该适配器类的作用是类似于 AOP 的功能，再调用具体的实现类之前，先通ExtensionLoader.getExtensionLoader(Registry.class).getExtension(extName);根据 extName 去 loader 具体的实现类，然后再去调用实现类的相应的方法。 分析上面代码中的一句: 1String extName = url.getParameter(&quot;registry&quot;, &quot;zookeeper&quot;); extName 可以通过 url 进行传递，默认值为 zookeeper, 该默认值即为我们定义的接口上的注解 @SPI 里的内容，上文我们定义的 @SPI(&quot;zookeeper&quot;)，所以这里的默认值为 zookeeper, 当 url 中没有对应的参数时，我们会去拿默认值。 我们可以修改 Main 测试程序，增加 key 为 registry 的 parameter 1234567891011public static void main(String[] args) { URL url = URL.valueOf(&quot;test://localhost/test&quot;).addParameter(&quot;service&quot;, &quot;helloService&quot;) .addParameter(&quot;registry&quot;,&quot;etcd&quot;); Registry registry = ExtensionLoader.getExtensionLoader(Registry.class).getAdaptiveExtension(); String register = registry.register(url, &quot;maple&quot;); System.out.println(register); } 在 URL 中增加 Key，并设置值为 etcd，运行程序，结果如下： 1209-20 23:44:00 009 main INFO - 服务: helloService 已注册到 Etcd 上，备注: mapleEtcd register already! 实现类已经切换为 EtcdRegistry 了。 @Adaptive 注意细节@Adaptive 源码 123public @interface Adaptive { String[] value() default {};} 细心的读者已经发现了 @Adaptive 有value这个属性。上文在接口方法上定义的 @Adaptive 是没有设置值的。如果没有定义值，Dubbo 默认会使用一种策略生成。这种策略是将类名定义的驼峰法则转换为小写，并以 . 号区分。 例如上文的接口名为 Registry，那么这个Key 值就是 registry。如果接口名为 HelloWorld，Key 值就为 hello.world。 当然如果 @Adaptive 是有值的话，优先按里面的这个值来作为 Key，例如 Dubbo 框架中的接口 RegistryFactory ,该接口的自适应类将会从 URL 以 protocol 为 key 来找实现类的 extName。 12345@SPI(&quot;dubbo&quot;)public interface RegistryFactory { @Adaptive({&quot;protocol&quot;}) Registry getRegistry(URL url);} 总结Dubbo Adaptive 模式在整个框架中运用十分广泛，如果用户没有在 URL 中进行自定义，Dubbo 默认会去加载扩展点接口上 @SPI 标注的内容,如果此注解没有值，那么我们就必须要在 URL 中进行值的传递了。如果我们想覆盖 Dubbo 默认的实现策略。可以通过在 URL 中增加 key-value 的形式来改变。 这样一个组件充分体现了设计模式,对修改关闭，对扩展开放的原则。当我们想自己实现 Dubbo 中的某个组件时，我们完全可以通过 Dubbo Adaptive 来动态的切换程序使用我们提供的组件。 彻底理解 Dubbo SPI 模式，以及 Adaptive 自适应类, Activate 激活类等，是看 Dubbo 源码的基础。如果我们想十分流畅的去分析 Dubbo 内部其他组件的实现机制，第一道要跨过的坎便是 Dubbo SPI。","link":"/p/22fedb28.html"},{"title":"APP接口安全TOKEN设计","text":"你是否真的需要登录功能？把这个问题放在最前面并不是灌水，而是真的见过很多并不需要登录的APP去做了登录功能，或者是并不需要强制登录的APP把登录作为启动页。用户对你的APP一无所知，你就要求对方注册并登录，除非APP本身已经很有名气或者是用户有强需求，否则正常人应该会直接把它删掉。比较温和的方式是将一些并不需要登录，但可以给用户带来帮助的东西，第一时间展现给他们，让他们产生兴趣，再在合适的时机引导他们注册（比如使用需要使用更高级的功能，或用户需要收藏某个喜欢的信息时）。 登录和注册要足够简单这是小小的手机端，用再好的输入法，打字也是不方便的，所以别把登录页设计得需要填很多东西。如果有可能的话，只填手机号，让用户收到短信验证码就完成注册是最好不过的了。想获得更多信息？想想大公司的APP是怎么做的，他们会告诉用户，现在的个人资料完善程度是30%，如果想获得更多积分，你需要填完。tips:如果你想发布在Appstore并且同时包含注册功能，那么注册页面必须做一个用户许可协议的链接，否则有可能通不过审核。 实现登录后的session有几种方式？APP当浏览器用，直接载入远程页面这种情况是很多偷懒的程序员或者傻X的老板选择的方式，因为做起来实在太快。如果本身网站是响应式布局，那么很有可能不需要做什么更改，就只要在开发时打开首页就好了，这样Hybird的APP外壳就纯粹成为了一个浏览器。但比起这样做带来的无数缺点来，开发速度快的优点几乎可以忽略不计。首先，在网络环境不佳时，纯大白页，用户体验0；然后，CSS和JS等资源不在本地，需要远程载入，如果使用了bootstrap之类的框架，那用户为了开一下APP而耗费的流量真是令人感动；再然后，网页里常用的jquery，在手机的webview里速度并不理想，而如果是非ajax的网页那就更糟心了，每次操作都要跳转和页面渲染，要让人把它当成APP那实在是笑话。再再然后，这样的所谓APP，要通过Appstore的审查，那是做梦的（除非审核员当天闹肚子严重，拿着纸巾奔向厕所前误点了通过……），苹果的要求是，这得是APP，而不能是某个网站做成APP的样子，那样的情况适合做Web APP。而据我所知，国内几个较大的Android市场，这样的APP也是无法通过审核的。 调用后端接口这是个很好的时代，因为无论后端你是用Java、PHP，还是node.js，都可以通过xml、json来和APP通讯。把刚才那个用APP当浏览器使的案例的所有缺点反过来看，就是这样做的优点，在优化完善的情况下体验接近原生，而且通讯流量极少，通过各种审核也是妥妥的。tips:通过plus对象中的XMLHttpRequest来Get、Post远程的后端接口，或者使用Mui中封装好的AJAX相关函数。 插一段代码，我把mui的ajax又做了进一步的封装，对超时进行了自动重试，而对invalid_token等情况也做相应处理： 12345678910111213141516171819202122232425mui.web_query = function(func_url, params, onSuccess, onError, retry){ var onSuccess = arguments[2]?arguments[2]:function(){}; var onError = arguments[3]?arguments[3]:function(){}; var retry = arguments[4]?arguments[4]:3; func_url = 'http://www.xxxxxx.com/ajax/?fn=' + func_url; mui.ajax(func_url, { data:params, dataType:'json', type:'post', timeout:3000, success:function(data){ if(data.err === 'ok'){ onSuccess(data); } else{ onError(data.code); } }, error:function(xhr,type,errorThrown){ retry--; if(retry &gt; 0) return mui.web_query(func_url, params, onSuccess, onError, retry); onError('FAILED_NETWORK'); } })}; 123456789101112131415var onError = function(errcode){ switch(errcode){ case 'FAILED_NETWORK': mui.toast('网络不佳'); break; case 'INVALID_TOKEN': wv_login.show(); break; default: console.log(errcode); }};var params = {per:10, pageno:coms_current_pageno};mui.web_query('get_com_list', params, onSuccess, onError, 3); 调用后端接口怎么样才安全？在APP中保存登录数据，每次调用接口时传输程序员总能给自己找到偷懒的方法，有的程序为了省事，会在用户登录后，直接把用户名和密码保存在本地，然后每次调用后端接口时作为参数传递。真省事儿啊！可这种方法简单就像拿着一袋子钱在路上边走边喊“快来抢我呀！快来抢我呀！”，一个小小的嗅探器就能把用户的密码拿到手，如果用户习惯在所有地方用一个密码，那么你闯大祸了，黑客通过撞库的方法能把用户的所有信息一锅端。 登录时请求一次token，之后用token调用接口这是比较安全的方式，用户在登录时，APP调用获取token的接口（比如http://api.abc.com/get_token/），用post将用户名和密码的摘要传递给服务器，然后服务器比对数据库中的用户信息，匹配则返回绑定该用户的token（这一般翻译为令牌，很直观的名字，一看就知道是有了这玩意，就会对你放行），而数据库中，在用户的token表中也同时插入了这个token相关的数据：这个token属于谁？这个token的有效期是多久？这个token当前登录的ip地址是？这个token对应的deviceid是？……这样即便token被有心人截获，也不会造成太大的安全风险。因为没有用户名和密码，然后如果黑客通过这个token伪造用户请求，我们在服务器端接口被调用时就可以对发起请求的ip地址、user-agent之类的信息作比对，以防止伪造。再然后，如果token的有效期设得小，过一会儿它就过期了，除非黑客可以持续截获你的token，否则他只能干瞪眼。（插一句题外话：看到这里，是不是明白为什么不推荐在外面随便接入来历不明的wifi热点了？）tips:token如何生成？ 可以根据用户的信息及一些随机信息（比如时间戳）再通过hash编码（比如md5、sha1等）生成唯一的编码。tips:token的安全级别，取决于你的实际需求，所以如果不是涉及财产安全的领域，并不建议太严格（比如用户走着走着，3G换了个基站，闪断了一下IP地址变了，尼玛token过期了，这就属于为了不必要的安全丢了用户体验，当然如果变换的IP地址跨省的话还是应该验证一下的，想想QQ有时候会让填验证码就明白了）。tips:接口在返回信息时，可以包含本次请求的状态，比如成功调用，那么result[‘status’]可能就是’success’，而反之则是’error’，而如果是’error’，则result[‘errcode’]中就可以包含错误的原因，比如errcode中是’invalid_token’就可以告诉APP这个token过期或无效，这时APP应弹出登录框或者用本地存储的用户名或密码再次请求token（用户选择“记住密码”，就应该在本地保存用户名和密码的摘要，方法见plus.storage的文档）。 再插点代码，基于plus.storage的用户信息类，注意：需要在plusReady之后再使用。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263function UserInfo(){};//清除登录信息UserInfo.clear = function(){ plus.storage.removeItem('username'); plus.storage.removeItem('password'); plus.storage.removeItem('token');}//检查是否包含自动登录的信息UserInfo.auto_login = function(){ var username = UserInfo.username(); var pwd = UserInfo.password(); if(!username || !pwd){ return false; } return true;}//检查是否已登录UserInfo.has_login = function(){ var username = UserInfo.username(); var pwd = UserInfo.password(); var token = UserInfo.token(); if(!username || !pwd || !token){ return false; } return true;};UserInfo.username = function(){ if(arguments.length == 0){ return plus.storage.getItem('username'); } if(arguments[0] === ''){ plus.storage.removeItem('username'); return; } plus.storage.setItem('username', arguments[0]);};UserInfo.password = function(){ if(arguments.length == 0){ return plus.storage.getItem('password'); } if(arguments[0] === ''){ plus.storage.removeItem('password'); return; } plus.storage.setItem('password', arguments[0]);};UserInfo.token = function(){ if(arguments.length == 0){ return plus.storage.getItem('token'); } if(arguments[0] === ''){ plus.storage.removeItem('token'); return; } plus.storage.setItem('token', arguments[0]);}; 这样当用户启动APP或使用了需要登录才能使用的功能时，就可以使用UserInfo.has_login()来判断是否已经登录，如果已登录，则使用UserInfo.token()来获取到token数据，作为参数调用远程的后端接口。 123456if(UserInfo.has_login()){ //打开需要展示给用户的页面，或者是调用远端接口}else{ wv_login.show('slide-in-up'); //从底部向上滑出登录页面} 在登录页面中，用户输入了用户名和密码后，并点击了”登录“按钮，我们下一步做什么？再插段代码（注意：此处使用的是我刚才代码中扩展的web_query函数，你也可以直接使用mui的ajax）： 123456789101112131415161718192021222324252627282930function get_pwd_hash(pwd){ var salt = 'hbuilder'; //此处的salt是为了避免黑客撞库，而在md5之前对原文做一定的变形，可以设为自己喜欢的，只要和服务器验证时的salt一致即可。 return md5(salt + pwd); //此处假设你已经引用了md5相关的库，比如github上的JavaScript-MD5}//这里假设你已经通过DOM操作获取到了用户名和密码，分别保存在username和password变量中。var username = xxx;var password = xxx;var pwd_hash = get_pwd_hash(password);var onSuccess = function(data){ UserInfo.username(username); UserInfo.password(pwd_hash); UserInfo.token(data.token); //把获取到的token保存到storage中 var wc = plus.webview.currentWebview(); wc.hide('slide-out-bottom'); //此处假设是隐藏登录页回到之前的页面，实际你也可以干点儿别的}var onError = function(errcode){ switch(errcode){ case 'INCORRECT_PASSWORD': mui.toast('密码不正确'); break; case 'USER_NOT_EXISTS': mui.toast('用户尚未注册'); break; }}mui.web_query('get_token', {username:username,password:pwd_hash}, onSuccess, onError, 3); 更安全一点，获取token通过SSL刚才的方法，机智一点儿的读者大概会心存疑虑：那获取token时不还是得明文传输一次密码吗？是的，你可以将这个获取token的地址，用SSL来保护（比如https://api.abc.com/get_token/），这样黑客即使截了包，一时半会儿也解不出什么信息。SSL证书的获取渠道很多，我相信你总有办法查到，所以不废话了。不过话说namecheap上的SSL证书比godaddy的要便宜得多……（这是吐槽）tips:前段时间OpenSSL漏洞让很多服务器遭殃，所以如果自己搭服务器，一定记得装补丁。tips:可以把所有接口都弄成SSL的吗？可以。但会拖慢服务器，如果是配置并不自信的VPS，建议不折腾。 如果更安全呢？还记得刚才APP向服务器请求token时，可以加入的用户信息吗？比如用户的设备deviceid。如果我们在调用接口时，还附带一个当前时间戳参数timestamp，同时，用deviceid和这个时间戳再生成一个参数sign，比如 md5(deviceid timestamp token)这样的形式。而服务端首先验证一下参数中的时间戳与当前服务器时间是否一致（误差保持在合理范围内即可，比如5分钟），然后根据用户保存在服务器中的deviceid来对参数中的时间戳进行相同的变形，验证是否匹配，那便自然“更更安全”了。tips:如果对整个调用请求中的参数进行排序，再以deviceid和timestamp加上排序后的参数来对整个调用生成1个sign，黑客即使截获sign，不同的时间点、参数请求所使用的sign也是不同的，难以伪造，自然会更安全。当然，写起来也更费事。tips:明白了原理，整个验证过程是可以根据自己的需求改造的。","link":"/p/821bbecd.html"},{"title":"🍎 Dubbo SPI 之扩展点自动包装 Wrapper 类","text":"之前的文章我们分析了 Dubbo 的扩展点自适应机制。Dubbo SPI 主要思想也是来自于 JDK 原生的 SPI 机制。框架定义好扩展点接口，服务提供者实现接口。框架可以通过SPI机制动态的将服务提供商切入到应用中。使我们的程序可以面向接口，对扩展开放。 Dubbo SPI 与 JDK SPIJDK SPI 需要在 classpath 下 META-INF/services 目录下创建以扩展点接口全限定名命名的文件，里面内容为实现类的名称(完整包名)，多个实现类换行分隔。文件名称: JDK加载扩展点实现类的方式: 1Iterator&lt;Registry&gt; registryImpls = ServiceLoader.load(Registry.class).iterator(); 结论JDK SPI 会加载 classpath 下的所有 META-INF/services 下的所有接口对应的实现类。如果该实现类在 classpath 存在，则会通过ServiceLoader加载出来。如果有多个实现类，多个实现类都会被加载出来，用户则会选择使用哪个。 Dubbo SPI 改进 不一次性实例化扩展点所有实现，再用到的时候，再选择性加载，可以减少资源浪费。 扩展点加载失败异常跑出更明确的信息 提供扩展点实现类与实现类之间的Wrapper 操作，可以用来聚合公共部分逻辑。 提供 IOC 和 AOP 等功能。 Dubbo 扩展点包装 Wrapper 类一个典型的Wrapper类如下: 1234567891011121314151617181920public class CommonRegistry implements Registry { // 持有 扩展点接口 private Registry registry; // 构造器注入 public CommonRegistry(Registry registry) { this.registry = registry; } @Override public String register(URL url, String msg) { // doSomething return registry.register(url,msg); } @Override public String discovery(URL url, String content) { // doSomething return registry.register(url,msg); }} 分析上面的包装类，我们得出 Dubbo 认为的包装类需要满足的两个条件 1.持有扩展点接口对象属性，并通过构造器方式初始化该属性 2.这个类也要实现扩展点接口类，并在实现方法中进行增强操作 Wrapper 包装类实战 上一篇文章 [Dubbo SPI 之 Adaptive 自适应类] 我们介绍过两个注册中心的实现。这里我们有一个新的需求，需要对每一个注册中心的注册服务和发现服务统计一下耗时，增加一些共有逻辑。所以我们定义一个 Wrapper 类。 1234567891011121314151617181920212223public class CommonRegistry implements Registry { private Logger logger = LoggerFactory.getLogger(CommonRegistry.class); // 持有 扩展点接口 private Registry registry; // 构造器注入 public CommonRegistry(Registry registry) { this.registry = registry; } @Override public String register(URL url, String msg) { long begin = System.currentTimeMillis(); String register = registry.register(url, msg); long end = System.currentTimeMillis(); logger.info(&quot;register method 处理耗时 cost: {} ms&quot;, end - begin); return register; } @Override public String discovery(URL url, String content) { //...实现同上 }} 在 META-INF/dubbo/com.maple.spi.Registry里面增加 wrapper 类的信息： 1common=com.maple.spi.impl.CommonRegistry 测试 Main 1234567891011public static void main(String[] args) { URL url = URL.valueOf(&quot;test://localhost/test&quot;) .addParameter(&quot;service&quot;, &quot;helloService&quot;) .addParameter(&quot;registry&quot;,&quot;etcd&quot;); //.addParameter(&quot;registry&quot;,&quot;zookeeper&quot;); Registry registry = ExtensionLoader.getExtensionLoader(Registry.class) .getAdaptiveExtension(); System.out.println(registry.register(url, &quot;maple&quot;););} 分别尝试使用 etcd 和 zookeeper，控制台打印如下： 12345678//Etcd09-26 00:55:16 707 main INFO - 服务: helloService 已注册到 Etcd 上，备注: maple09-26 00:55:16 709 main INFO - register method 处理耗时 cost: 2 msEtcd register already! // zookeeper09-26 00:56:17 282 main INFO - 服务: helloService 已注册到zookeeper上，备注: maple09-26 00:56:17 284 main INFO - register method 处理耗时 cost: 2 msZookeeper register already! 我们看到了 register method 处理耗时 cost: 2 ms 这条日志，说明 CommonRegistry 的逻辑已经运行了。程序先构造 CommonRegistry，从它的构造器中传入的是扩展点实现类，程序会先调用wrapper类对应的方法， 然后在方法内部再调用扩展点实现类的对应方法。类似于装饰器模式，为扩展点实现类增强了功能。通过这种设计模式，我们可以将多个扩展点实现共用的公共逻辑都移到此类中来。 Wrapper 类不属于候选的扩展点实现 Wrapper 类不属于扩展点实现，我们可以通过如下代码进行验证: 12345Set&lt;String&gt; extens = ExtensionLoader .getExtensionLoader(Registry.class) .getSupportedExtensions();//结果[etcd, zookeeper] 通过 getSupportedExtensions 可以获取扩展点接口 Registry 当前所有的服务扩展实现的 key 值。控制台的结果只有 etcd 和 zookeeper。 因此，wrapper 不属于 扩展点实现，同理 上一篇文章介绍的自适应类 Adaptive， 也不属于扩展点实现。 总结通过本文总结 JDK SPI 原理和使用方式，然后和 Dubbo SPI 进行对比。 Dubbo 扩展点自动包装Wrapper类，类似与AOP，为扩展点实现增加更多前置或者后置功能模块。实现原理采用装饰器设计模式，将真正的扩展点实现包装在Wrapper类中。扩展点的Wrapper可以有多个，可以根据需求新增。 &emsp;&emsp;扫一扫，关注我的微信公众号 ![公众号.png](https://upload-images.jianshu.io/upload_images/6393906-457a99e16106e3a3.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/600)","link":"/p/ac54f348.html"},{"title":"🍎 Dubbo实战 整合 SpringBoot 实现自动装配","text":"如今 Spring Boot 在微服务领域已十分风靡，开箱即用的特性，简化了很多开发工作。而 Dubbo 在 2017 年重新得到维护以后，社区逐渐活跃，Dubbo RPC 十分优秀，本文我们将通过一个例子来构建一个基于 Spring Boot 的Dubbo 微服务工程。 Dubbo Spring Boot Starter 项目 我们在采用 Dubbo 作为 微服务框架时，可以通过依赖这个项目来轻松整合 SpringBoot 上面是 Dubbo Spring Boot 工程地址 。Dubbo Spring Boot 工程致力于简化 Dubbo RPC 框架在 Spring Boot 应用场景的开发。同时也整合了 Spring Boot 特性： SpringBoot Dubbo 项目实战 我们将实现一个简单的基于SpringBoot 和 Dubbo 的微服务例子来进行讲解。项目采用多模块的形式打包。分为如下三个工程： dubbo-boot-api统一使用的API工程，提供给生产者和消费者，包括服务接口等，实体模型等。 dubbo-boot-consumer服务消费端，该工程将会提供web服务，并调用 Dubbo 提供的微服务。 dubbo-boot-provider服务提供方，提供服务供消费者进行调用 POM 依赖 项目根 POM 文件 需要依赖 SpringBoot 的 Parent 工程 作为 父工程以方便管理Spring的版本，我们采用的版本号为 Spring Boot 2.0.0.RELEASE 12345&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.0.0.RELEASE&lt;/version&gt;&lt;/parent&gt; 服务提供者 (dubbo-boot-provider) 、服务消费者 (dubbo-boot-consumer) 都需要依赖 dubbo 整合 Spring 的dubbo-spring-boot-starter工程，以及 spring-boot-starter-web，通过 web 作为服务启动运行载体。 12345678910111213&lt;!-- Dubbo 整合 Boot Dubbo 依赖 --&gt;&lt;dependency&gt; &lt;groupId&gt;com.alibaba.spring.boot&lt;/groupId&gt; &lt;artifactId&gt;dubbo-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;2.0.0&lt;/version&gt;&lt;/dependency&gt;&lt;!-- Spring Boot Web 依赖 --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;&lt;/dependency&gt; API 工程 dubbo-boot-api api工程主要提供实体类和公用服务接口， provider、consumer 都会依赖它 实体类 City 123public class City implements Serializable { private String name; private String from; 服务接口 CityService 12345678public interface CityService { /** * 根据城市名称，查询城市信息 * * @param cityName */ City findCityByName(String cityName);} Provider 服务提供工程 dubbo-boot-provider服务提供实现 CityServiceImpl 12345678910111213@Service( version = &quot;${demo.service.version}&quot;, application = &quot;${dubbo.application.id}&quot;, protocol = &quot;${dubbo.protocol.id}&quot;, registry = &quot;${dubbo.registry.id}&quot;)public class CityServiceImpl implements CityService { public City findCityByName(String cityName) { System.out.println(&quot;request cityName: &quot; + cityName); return new City(&quot;武汉&quot;, &quot;湖北&quot;); }}启动类 AppProvider 使用非 web 的形式启动 SpringBoot 容器，提供 Dubbo Rpc 服务 12345678910@SpringBootApplication@EnableDubboConfigurationpublic class App { public static void main(String[] args) { //使用非 Web 环境启动 Spring容器，提供dubbo rpc 服务 new SpringApplicationBuilder().sources(AppProvider.class) .web(WebApplicationType.NONE) .run(args); }} application.properties12345678910111213141516# Spring boot applicationspring.application.name = dubbo-provider-demo## Provider类配置demo.service.version=1.0.0dubbo.application.id = dubbo-boot-providerdubbo.application.name = dubbo-boot-provider## 使用通讯协议、暴露端口dubbo.protocol.id = dubbodubbo.protocol.name = dubbodubbo.protocol.port = 20880## 注册中心 （不使用，直接本地互连）dubbo.registry.id = my-registrydubbo.registry.address = N/A Consumer 消费者工程 dubbo-boot-provider Spring Boot Controller 类，提供 Rest 接口。引用 Dubbo 服务接口 CityService 12345678910111213@RestControllerpublic class HelloController { @Reference(version = &quot;${demo.service.version}&quot;, application = &quot;${dubbo.application.id}&quot;, url = &quot;${dubbo.service.url}&quot;) private CityService cityService; @RequestMapping(&quot;/hello&quot;) public Object hello() { return cityService.findCityByName(&quot;武汉&quot;); }} 启动类 提供 web 服务供前端调用 1234567@SpringBootApplicationpublic class AppConsumerServer { public static void main(String[] args) { SpringApplication.run(AppConsumerServer.class, args); }} application.properties 本例子没有采用注册中心，而是通过本地 url 互相直连服务端进行调用。 123456789spring.application.name=dubbo-boot-consumerdemo.service.version=1.0.0dubbo.application.id=dubbo-boot-consumerdubbo.application.name=dubbo-boot-consumer# 通过直连方式dubbo.service.url=dubbo://127.0.0.1:20880 测试分别运行启动服务端(AppServer) 和消费端(AppConsumerServer) 类。然后打开浏览器访问 localhost:8080/hello 结果显示已经调用成功。整个执行链为，前端访问 url 调用消费端 Spring Rest接口，Controller 里通过 Dubbo Rpc 调用 服务端提供的服务，然后返回。 总结采用 Spring Boot 工程，引入 Dubbo 整合 Spring Boot 的 依赖，将会使我们非常简单轻松的使用 Dubbo 来提供微服务。我们可以充分利用 Spring Boot 的 注解驱动、自动装配、外部化配置、Actuator 监控等特性，来轻松管理基于Dubbo 的微服务。 社区提供的 dubbo-spring-boot-starter 工程 整合了与 Spring Boot 这些自动配置、依赖等。所以下一步我们将会研究 它是如何实现与 Spring Boot 无缝整合的。 推荐最后推荐一下本人微信公众号，欢迎大家关注。","link":"/p/b7f8f92f.html"},{"title":"etcd v3基本知识概览","text":"etcd命令行 v3 api 设置键、修改键 1etcdctl put /maple value 删除键 1234etcdctl del /maple#删除所有/test前缀的节点etcdctl del /test --prefix 查询Key 12345etcdctl get /test/ok# 前缀查询etcdctl get /test/ok --prefix# 查询所有键etcdctl --prefix --keys-only=true get / watch key 1234etcdctl watch /maple/services#watch子节点etcdctl watch /maple/services --prefix 申请租约、授权租约 1234567891011121314# 申请租约etcdctl lease grant 40 lease 4e5e5b853f528859 granted with TTL(40s)# 授权租约etcdctl put --lease=4e5e5b853f528859 /maple/s 123# 撤销etcdctl lease revoke 4e5e5b853f5286cc#租约续约etcdctl lease keep-alive 4e5e5b853f52892b 临时节点 在实现服务发现时，我们一般都会用到ZooKeeper的临时节点，只要客户端与ZooKeeper之间的session会话没有中断（过期），那么创建的临时节点就会存在。当客户端掉线一段时间，对应的zk session会过期，那么对应的临时节点就会被自动删除。 在etcd中并没有临时节点的概念，但是支持lease租约机制。 什么叫lease？其实就是etcd支持申请定时器，比如：可以申请一个TTL=10秒的lease（租约），会返回给你一个lease ID标识定时器。你可以在set一个key的同时携带lease ID，那么就实现了一个自动过期的key。 在etcd中，一个lease可以关联给任意多的Key，当lease过期后所有关联的key都将被自动删除。 那么如何实现临时节点呢？ 首先申请一个TTL=N的lease，然后set一个key with lease作为自己的临时节点，在程序中定时的为lease（租约）进行续约，也就是重置TTL=N，这样关联的key就不会过期了。 事件机制 在我们用ZooKeeper实现服务发现时，我们一般会getChildrenAndWatch来获取一个目录下的所有在线节点，这个API会先获取当前的孩子列表并同时注册了一个观察器。每当ZooKeeper发现子节点有变动的时候，就会watch回调给客户端（同时关闭观察器,），此时我们会再次调用getChildrenAndWatch再次获取最新的子节点列表并重新注册观察器。 Zookeeper的事件模型？简单的来说，ZooKeeper提供了一个原子API，它先获取当前状态，同时注册一个观察器，当后续变化发生时会发送一次通知到客户端：获取并观察-&gt;收到变化事件-&gt;获取并观察-&gt;收到变化事件-&gt;……，如此往复。 ZooKeeper的事件模型非常可靠，不会出现发生了更新而客户端不知道的情况，但是特点也很明显：事件不包含数据，仅仅是通知变化。多次连续的更新，通知会合并成一个；即，客户端收到通知再次拉取数据，会跳过中间的多个版本，只拿到最新数据。这些特点并不是缺点，因为一般应用只关注最新状态，并不关注中间的连续变化。 那么etcd的事件模型呢?在现在，你只需要记住etcd的事件是包含数据的，并且通常情况下连续的更新不会被合并通知，而是逐条通知到客户端。 具体etcd事件模型如何工作，要求对etcd的K-V存储原理先做了解，所以接下来我会结合一些简单的源码，说一下etcd的存储模型，最后再来说它的事件模型。","link":"/p/5d3c61fa.html"},{"title":"程序员如何保持优秀","text":"程序员如何保持优秀 本文是英文原文 How to be an Excellent Programmer for Many Years 的翻译, 摘抄自 oldrat lee 的博客 1.小范围的选择一些有用技术，透彻的学习它们，拥抱它们。然后不断的扩展这个范围。 2.理解各种数据结构的优点和缺点，包括它们在内存中和在硬盘上的各自表现。 3.理解各种算法的优点和缺点。 4.了解你的工作领域。关上电脑，去做你的用户们在做的事。 5.有准备，有愿望，有能力在任何时候投入到多种技术层面中。你必须知道表象下的技术原理。在“各个技术层面的掌握程度”和“编程能力”上有着密切的联系。 6.发挥你的想象力。永远都要问，“有更好的方法吗？”跳出常规思维约束。最好的解决方案也许还没有被发现。 7.优秀程序员：我优化代码。更优秀程序员：我设计数据。最优秀程序员：他们的不同之处是什么？ 8.正确的构造你的数据。任何的缺陷都将造成你的代码里无尽的技术债务。 9.正确的命名事物。使用“动词-形容词-名词”格式来命名程序和函数。变量名要足够长，尽量短，有意义。如果其他程序员不能够理解你的代码，说明你写的不够清楚。在大多数情况下，针对下一个程序员而编码要比针对环境而编码重要的多。 10.把分析和编程分离开做。它们不是同类的事物，需要不同类型的劳力资源，需要在完全不同的时间和地点分开做。如果同时做它们，你一样都做不好。(我喜欢在一天的末尾做不涉及技术的分析，而在第二天早上进行编程。) 11.永远不要图省事走近道。永远不要把相同的代码部署两次。永远不要把一个变量命名成另一个变量名的一部分。也许你不明白这些规则，也许你要辩解。但如果你是遵守着这样做的，这些规则就会约束你正确的构造你的程序。图省事的做法是让那些低等级的程序员永远停留在低等级的原因。 12.学习如何测评程序性能。你会惊奇的发现从中能学到很多之外的知识。 13.学会区别对待问题细节和问题后果。问题细节不会导致太大的差别，而问题后果能导致世界灭亡。只关注后果。 14.密切关注你的用户/客户/管理人员。帮助他们认清楚他们的“what”，这比帮助他们明白他们的“how”要重要的多。 15.写一个框架，不论你是否打算用它。你将从中学到从其它途径中学不到的东西。 16.把你知道的东西教给他人——通过口口交流或通过写作。最终这将成为教育自己的机会。 17.永远要对你的客户/用户说“Yes”，即使在你不确定的情况下。90%的情况下，你会最终找到方法实现它。10%的机会，你将会去向他们道歉。这是重要的个人成长中付出的一点小代价。 18.寻找别人的做出神奇的事情但却一滩糊涂的代码。重构它。然后丢掉它，并发誓自己永远不要犯他们犯下的相同错误。(这样的程序你会发现很多。) 19.数据永远 &gt; 理论或观点。通过开发东西来学习数据。 20.有可能的话，开创自己的业务(服务或产品)。你将从中学到很多你做雇员永远学不到的关于编程的知识。 21.如果不喜爱你现在的工作，就换一个。","link":"/p/c81b0f21.html"},{"title":"hexo+github搭建博客","text":"使用github pages服务搭建博客的好处有：全是静态文件，访问速度快；免费方便，不用花一分钱就可以搭建一个自由的个人博客，不需要服务器不需要后台；可以随意绑定自己的域名，不仔细看的话根本看不出来你的网站是基于github的；数据绝对安全，基于github的版本管理，想恢复到哪个历史版本都行；博客内容可以轻松打包、转移、发布到其它平台； 初始化hexo之后，要安装这个插件 这个插件的主要作用是站内搜索，insight.js依赖这个包管理 1$ npm install hexo-generator-json-content@2.2.0 --save 安装完成之后，检查版本 1$ npm hexo-generator-json-content -v 配置SSH Key 通过git bash 执行如下命令 1$ cd ~/. ssh #检查本机已存在的ssh密钥 如果提示：No such file or directory 说明你是第一次使用git。 1ssh-keygen -t rsa -C &quot;yourname@qq.com&quot; 然后连续3次回车，最终会生成一个文件在用户目录下，打开用户目录，找到.ssh\\id_rsa.pub文件，记事本打开并复制里面的内容，打开你的github主页，进入个人设置 -&gt; SSH and GPG keys -&gt; New SSH key： 测试是否成功 1$ ssh -T git@github.com # 注意直接敲这条命令,邮箱地址不用改 如果提示Are you sure you want to continue connecting (yes/no)?，输入yes，然后会看到： 1Hi leihuazhe! You’ve successfully authenticated, but GitHub does not provide shell access. 看到这个信息说明SSH已配置成功！ 此时你还需要配置： 12$ git config --global user.name &quot;leihuazhe&quot;// 你的github用户名，非昵称$ git config --global user.email &quot;xxx@qq.com&quot;// 填写你的github注册邮箱 这是git的初始全局配置 hexo的部分命令 123456$ cnpm install -g hexo #安装hexo$ hexo init #初始化$ hexo g #编译生成public$ hexo s #启动本地服务，可以在localhost:4200进行预览$ hexo d #推送到github上,下面详细介绍$ hexo clean #删除public文件夹 如果你一切都配置好了，发布上传很容易，一句hexo d就搞定，当然关键还是你要把所有东西配置好。 首先，ssh key肯定要配置好。 其次，配置_config.yml中有关deploy的部分： 1234deploy: type: git repository: git@github.com:liuxianan/liuxianan.github.io.git branch: master 如果都配置好了，还时报下面的错 12$ hexo dERROR Deployer not found: git 试下安装如下插件 1cnpm install hexo-deployer-git --save 然后一切ok，hexo博客搭建成功 常见问题 当我在另一台电脑上面把源码下载下来后，重新部署时，发现所有的目录都被上传到了github上 解决方法： 删除目录下的 .deploy_git 具体搭建请参考 END","link":"/p/1bda8925.html"},{"title":"HttpClient基础(一)","text":"HttpClient是 Apache Jakarta Common下的子项目,可以用来提供高效的、最新的、功能丰富的支持HTTP协议的客户端编程工具包，本文采用的HttpClient版本是4.4.1许多需要后台模拟请求的系统或者框架都用的是httpclient。所以作为一个java开发人员，有必要学一学。本文提供了一个简单的demo，供初学者参考。 使用HttpClient发送请求、接收响应很简单，一般需要如下几步即可： 创建CloseableHttpClient对象。 创建请求方法的实例，并指定请求URL。如果需要发送GET请求，创建HttpGet对象；如果需要发送POST请求，创建HttpPost对象。 如果需要发送请求参数，可可调用setEntity(HttpEntity entity)方法来设置请求参数。setParams方法已过时（4.4.1版本）。 调用HttpGet、HttpPost对象的setHeader(String name, String value)方法设置header信息，或者调用setHeaders(Header[] headers)设置一组header信息。 调用CloseableHttpClient对象的execute(HttpUriRequest request)发送请求，该方法返回一个CloseableHttpResponse。 调用HttpResponse的getEntity()方法可获取HttpEntity对象，该对象包装了服务器的响应内容。程序可通过该对象获取服务器的响应内容； 调用CloseableHttpResponse 的getAllHeaders()、getHeaders(String name)等方法可获取服务器的响应头。 释放连接。无论执行方法是否成功，都必须释放连接 下面是一个POST带参数请求的例子，访问天气网站,用到的HttpClient版本是4.4.1 12345678910111213141516171819202122232425262728293031323334353637public static String send(String url, Map&lt;String, String&gt; map, String encoding) throws IOException{ String body = &quot;&quot;; //1.创建对象 CloseableHttpClient httpClient = HttpClients.createDefault(); //2.创建请求方式 HttpPost post = new HttpPost(url); //3.装填参数 List&lt;NameValuePair&gt; nvp = new ArrayList&lt;&gt;(); if(map !=null){ for (Entry&lt;String, String&gt; entry : map.entrySet()) { nvp.add(new BasicNameValuePair(entry.getKey(), entry.getValue())); } } //4.设置参数到请求对象中 post.setEntity(new UrlEncodedFormEntity(nvp,encoding)); System.out.println(&quot;请求地址：----&quot;+url); System.out.println(&quot;请求参数：-----&quot;+nvp.toString()); //5.设置头部信息 post.setHeader(&quot;Content-type&quot;, &quot;application/x-www-form-urlencoded&quot;); post.setHeader(&quot;User-Agent&quot;, &quot;Mozilla/4.0 (compatible; MSIE 5.0; Windows NT; DigExt)&quot;); //6.执行请求 CloseableHttpResponse response = httpClient.execute(post); //7.获取结果 HttpEntity entity = response.getEntity(); if(entity!=null){ //按指定编码转换结果实体为String类型 System.out.println(&quot;entity----&quot;+entity); body = EntityUtils.toString(entity, encoding); } response.close(); return body;} 测试1234567891011121314151617181920212223public static void main(String[] args) throws IOException { String url=&quot;http://php.weather.sina.com.cn/iframe/index/w_cl.php&quot;; Map&lt;String, String&gt; map = new HashMap&lt;String, String&gt;(); map.put(&quot;code&quot;, &quot;js&quot;); map.put(&quot;day&quot;, &quot;0&quot;); map.put(&quot;city&quot;, &quot;武汉&quot;); map.put(&quot;dfc&quot;, &quot;1&quot;); map.put(&quot;charset&quot;, &quot;utf-8&quot;); String body = send(url1, map,&quot;utf-8&quot;); System.out.println(&quot;交易响应结果：&quot;); System.out.println(body); System.out.println(&quot;-----------------------------------&quot;); map.put(&quot;city&quot;, &quot;北京&quot;); body = send(url, map, &quot;utf-8&quot;); System.out.println(&quot;交易响应结果：&quot;); System.out.println(body); } 结果12345678请求地址：----http://php.weather.sina.com.cn/iframe/index/w_cl.php请求参数：-----[dfc=1, charset=utf-8, code=js, city=武汉, day=0]entity----org.apache.http.client.entity.DecompressingEntity@548e7350交易响应结果：(function(){var w=[];w['武汉']=[{s1:'晴',s2:'晴',f1:'qing',f2:'qing',t1:'28',t2:'20',p1:'≤3',p2:'≤3',d1:'无持续风向',d2:'无持续风向'}];var add={now:'2017-09-11 20:14:23',time:'1505132063',update:'北京时间09月11日17:10更新',error:'0',total:'1'};window.SWther={w:w,add:add};})();//0 注意，静态文件不接受post请求Apache、IIS、Nginx等绝大多数web服务器，都不允许静态文件响应POST请求，否则会返回HTTP/1.1 405 Method not allowed错误。 解决方法，修改nginx配置12345location ^~ /m/coupon { root /data/server/h5.weidian.com; error_page 405 =200 https://$host$request_uri;} 附各种请求的写法1.GET请求12345678910111213141516171819202122232425262728293031public class DoGET { public static void main(String[] args) throws Exception { // 创建Httpclient对象 CloseableHttpClient httpclient = HttpClients.createDefault(); // 创建http GET请求 HttpGet httpGet = new HttpGet(&quot;http://www.baidu.com/&quot;); CloseableHttpResponse response = null; try { // 执行请求 response = httpclient.execute(httpGet); // 判断返回状态是否为200 if (response.getStatusLine().getStatusCode() == 200) { String content = EntityUtils.toString(response.getEntity(), &quot;UTF-8&quot;); System.out.println(&quot;内容长度：&quot; + content.length()); } } finally { if (response != null) { response.close(); } httpclient.close(); } }} 2.带参数的GET请求123456789101112131415161718192021222324252627282930313233343536public class DoGETParam { public static void main(String[] args) throws Exception { // 创建Httpclient对象 CloseableHttpClient httpclient = HttpClients.createDefault(); // 定义请求的参数 URI uri = new URIBuilder(&quot;http://www.baidu.com/s&quot;).setParameter(&quot;wd&quot;, &quot;java&quot;).build(); System.out.println(uri); // 创建http GET请求 HttpGet httpGet = new HttpGet(uri); CloseableHttpResponse response = null; try { // 执行请求 response = httpclient.execute(httpGet); // 判断返回状态是否为200 if (response.getStatusLine().getStatusCode() == 200) { String content = EntityUtils.toString(response.getEntity(), &quot;UTF-8&quot;); System.out.println(content); } } finally { if (response != null) { response.close(); } httpclient.close(); } }} 3.POST请求1234567891011121314151617181920212223242526272829303132public class DoPOST { public static void main(String[] args) throws Exception { // 创建Httpclient对象 CloseableHttpClient httpclient = HttpClients.createDefault(); // 创建http POST请求 HttpPost httpPost = new HttpPost(&quot;http://www.oschina.net/&quot;); CloseableHttpResponse response = null; try { // 执行请求 response = httpclient.execute(httpPost); // 判断返回状态是否为200 if (response.getStatusLine().getStatusCode() == 200) { String content = EntityUtils.toString(response.getEntity(), &quot;UTF-8&quot;); System.out.println(content); } } finally { if (response != null) { response.close(); } httpclient.close(); } }} 4.带参数的POST请求123456789101112131415161718192021222324252627282930313233343536373839public class DoPOSTParam { public static void main(String[] args) throws Exception { // 创建Httpclient对象 CloseableHttpClient httpclient = HttpClients.createDefault(); // 创建http POST请求 HttpPost httpPost = new HttpPost(&quot;http://www.oschina.net/search&quot;); // 设置2个post参数，一个是scope、一个是q List&lt;NameValuePair&gt; parameters = new ArrayList&lt;NameValuePair&gt;(0); parameters.add(new BasicNameValuePair(&quot;scope&quot;, &quot;project&quot;)); parameters.add(new BasicNameValuePair(&quot;q&quot;, &quot;java&quot;)); // 构造一个form表单式的实体 UrlEncodedFormEntity formEntity = new UrlEncodedFormEntity(parameters); // 将请求实体设置到httpPost对象中 httpPost.setEntity(formEntity); CloseableHttpResponse response = null; try { // 执行请求 response = httpclient.execute(httpPost); // 判断返回状态是否为200 if (response.getStatusLine().getStatusCode() == 200) { String content = EntityUtils.toString(response.getEntity(), &quot;UTF-8&quot;); System.out.println(content); } } finally { if (response != null) { response.close(); } httpclient.close(); } } }","link":"/p/e103ddbe.html"},{"title":"Hello World","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub.i just change something by hexo-tag-aplayer Quick StartCreate a new post1$ hexo new &quot;My New Post&quot; More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","link":"/p/4a17b156.html"},{"title":"Jquery遍历与JS事件单独处理","text":"最近在工作上面碰到如下需求，要将下面三列中的大于100%的数据都以100%显示，小于的则不处理。由于报表数据是在后台组合的，每个指标间的数据都是取自缓存，如果直接在后台进行逻辑处理，会打乱很多业务处理流程，因此经过一番琢磨后，决定在前台页面进行修改，等报表组合完毕后。 需求分析 这里要注意的是，报表展示页面为静态的HTML文件，前后台是分离的，数据通过AJAX调用后台接口，因此，请求不同的ID会有不同的报表在相同的页面进行展示，如果直接在JS中写处理逻辑的话，会导致其他报表的TABLE相同的部分也会被处理，这显然不是我们需要的。 这是需求 这是处理后的结果 前台数据修改 通过Jquery在报表生成之后，对指定的数据进行修改 12345678910111213var str = &quot;0,1,2&quot;;function reset_percent(str){ var arr=str.split(&quot;,&quot;); if (arr.length&gt;0){ $(&quot;.table_body table tbody tr&quot;).each(function(i,n){ for (var j=0; j&lt;arr.length;j++){ if(parseInt($(n).children(&quot;td:eq(&quot;+parseInt(arr[j])+&quot;)&quot;).html())&gt;=100){ $(n).children(&quot;td:eq(&quot;+parseInt(arr[j])+&quot;)&quot;).html(&quot;100%&quot;); } } }) } } 分析,我们先分析报表的组成结构，类似于如下结构 123456789101112131415161718&lt;table&gt; &lt;thead&gt; &lt;tr&gt; &lt;th&gt;&lt;/th&gt; &lt;th&gt;&lt;/th&gt; &lt;th&gt;&lt;/th&gt; &lt;/tr&gt; &lt;/thead&gt;&lt;tbody&gt; &lt;tr&gt; &lt;td&gt;&lt;/td&gt; &lt;td&gt;&lt;/td&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt;&lt;/table&gt; 我们可以通过Jquery选择器先找到table，然后找到tbody，再找到tbody下面的tr，然后通过each函数对tr进行遍历，使得每个tr下面具体需要的第几个td的数据进行改变，因此代码如下 12345678910111213//重置 三列的百分比function reset_percent(str){ var arr=str.split(&quot;,&quot;); if (arr.length&gt;0){ $(&quot;.table_body table tbody tr&quot;).each(function(i,n){ for (var j=0; j&lt;arr.length;j++){ if(parseInt($(n).children(&quot;td:eq(&quot;+parseInt(arr[j])+&quot;)&quot;).html())&gt;=100){ $(n).children(&quot;td:eq(&quot;+parseInt(arr[j])+&quot;)&quot;).html(&quot;100%&quot;); } } }) } } 如上，我们通过遍历每一个tr元素，找到tr元素下面具体的td进行修改，我们在其他地方调用上面这个方法，传入需要改变的几列的字符串，需要注意的是，td的index是以0开头的，所以改变第一列td的话，就从0开始。 后台处理 后台报表模型里面添加，JS事件处理，即每一个报表都可以配置自己需要的JS Handler 事件，当然，这些事件提前写好在一个JS文件里，只是我们根据不同的报表去具体的调用。举个例子，报表A的模型里有一栏是写JS的，如下： 将配置写在模型的sql中进行保存，以XML格式保存，然后通过Simple XML进行解析，我之前也写过Simple XML解析XML的方式，传送门 接下来，我们在组装报表之前，和组装报表之后，分别判断从后台传来的结果是否包含额外的事件处理 12345678function build_table_simple(jsonData){ reset_title_link(); //是否有附加处理js if (additionHandle!=null &amp;&amp; additionHandle.execute_time==&quot;create_table_before&quot;){ eval(additionHandle.execute_function); } .... 省略 如果有要处理的话，通过eval()解析字符串，让字符串具有JS的事件处理能力，传来的字符串相当于调用了上面写的那个方法，并传入了具体需要修改的td列。 总结 我们在业务处理中，很多表格都是通过遍历来组成的，因此你无法手动去修改表格里面哪一行那一列具体的值。而且很多页面是公用的，他通过传入ID的不同展示不同的表格和数据，这样的话，你如果在页面引用的JS里面直接调用处理函数，这样其他的报表也会受到影响，因此，最好的方法就是，不同的报表配置不同的事后JS处理事件，存在数据库中，当调用这个报表时，也调用相对应的JS处理函数，这样需求也就解决了。 END","link":"/p/15049d29.html"},{"title":"玩转nginx  nginx常用配置之负载均衡","text":"nginx 作为静态文件服务器1234567891011121314server { listen 8001; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_connect_timeout 600; proxy_read_timeout 600; proxy_send_timeout 600; proxy_set_header X-Forwarded-For $http_x_forwarded_for; client_max_body_size 20m; location / { root /etc/nginx/html/store_app/dist/; index index.html; } nginx 反向代理到上述节点1234567891011121314server { listen 8000; root /etc/nginx/html/store_app; location ~* /store_app/ { autoindex on; rewrite ^/(.*)$ http://10.10.10.36:8001 permanent; break; } error_log /var/log/nginx/demo.log; access_log /var/log/nginx/demo.log;} 生产 nginx eywa 配置1234567891011121314151617181920212223242526272829303132333435363738394041424344454647upstream eywa { server 192.168.10.125:8081; server 192.168.20.115:8081; ip_hash;}server { listen 80; server_name eywa.today36524.com rewrite / https://eywa.today36524.com$uri permanent;}server { listen 443 ssl; server_name eywa.today36524.com; ssl_certificate /etc/nginx/cert/today36524.com.pem; ssl_certificate_key /etc/nginx/cert/today36524.com.key; ssl_protocols TLSv1 TLSv1.1 TLSv1.2; ssl_ciphers xxxxxxxxxxxxx xxxxxxx access_log /var/log/nginx/eywa-443.log error_log /var/log/nginx/eywa-error443.log proxy_connect_timeout 600; proxy_read_timeout 600; proxy_send_timeout 6000; gzip off; gzip_buffers 16 8k; gzip_comp_level 5; gzip_ location /{ send_timeout 300; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwardad_for; proxy_pass http://eywa; }}","link":"/p/cbcade0e.html"},{"title":"🎮 Play 入门与学习(五) 2.5.x 版本自定义 Action","text":"由于目前在公司使用的 Play 版本是 2.5.4，本章将会讲解一下对此版本 Action 的相关知识。 使用 ActionBuilder 构建一个通用的 Action12345678910object LogAction extends ActionBuilder[Request] { override def invokeBlock[A](request: Request[A], block: (Request[A]) =&gt; Future[Result]): Future[Result] = { val start = System.currentTimeMillis() block(request).map { result =&gt; val duration = System.currentTimeMillis() - start println(s&quot;请求 $request 耗时 $duration&quot;) result } }}","link":"/p/6e951315.html"},{"title":"🎮 Play 入门与学习(二) Action Composition","text":"本章将讲解 Action 的组成和原理,并且介绍了几种定义通用 Action 的方法。 Action composition Action 组成结构 Custom action builders 自定义 action builders我们有多种方法来声明一个 Action，使用 request 参数,不使用 request 参数, 使用 body parser 等等。实际上，并不止这些，我们将在异步编程一节进行讲述。 这些用于构建 actions 的方法实际上都是由一个名为 ActionBuilder 的 trait 定义的。而我们用来声明 Action 的 Action Object 只是这个 trait 的一个实例。通过实现自己的 ActionBuilder，您可以声明可重用的 action stack，然后可以使用它们来构建 actions。 让我们从日志修饰符(logging decorator) 的简单示例开始，我们希望记录对 action 的每次调用日志。 第一种方法是在 invokeBlock 方法中实现这个功能，ActionBuilder 构建的每一个 action 都会调用这个方法。 123456789import play.api.mvc._class LoggingAction @Inject() (parser: BodyParsers.Default)(implicit ec: ExecutionContext) extends ActionBuilderImpl(parser) { override def invokeBlock[A](request: Request[A], block: (Request[A]) =&gt; Future[Result])={ Logger.info(&quot;Calling action&quot;) block(request) }} 现在，我们可以在 controllers 中使用依赖注入来获取 LoggingAction 的一个实例，并且以使用普通 Action 的方式来使用它。 1234567class MyController @Inject()(loggingAction: LoggingAction, cc:ControllerComponents) extends AbstractController(cc) { def index = loggingAction { Ok(&quot;Hello World&quot;) }} Since ActionBuilder provides all the different methods of building actions, this also works with, for example, declaring a custom body parser: 由于 ActionBuilder 提供了创建 actions 所有不同的方法，所以我们也可以在自定义的 Action 中使用 body parser 等普通 Action 的功能。 123def submit = loggingAction(parse.text) { request =&gt; Ok(&quot;Got a body &quot; + request.body.length + &quot; bytes long&quot;)} 组合 actions Composing actions 在大多数应用程序中,我们希望有多个 action builders, 比如一些做不同类型的 authentication, 一些提供不同类型的通用功能组件,等等。 在这种情况下,我们不想为每一个 action builder 重写 loggingAction，我们需要定义一个可重用的方式来简化代码。可重用的操作代码可以通过包装操作（wrapping actions）来实现 123456789101112import play.api.mvc._case class Logging[A](action: Action[A]) extends Action[A] { def apply(request: Request[A]): Future[Result] = { Logger.info(&quot;Calling action&quot;) action(request) } override def parser = action.parser override def executionContext = action.executionContext} We can also use the Action action builder to build actions without defining our own action class: 我们也可以使用 Action action builder 来 创建 actions 而不需要定义我们自己的 action class 123456import play.api.mvc._def logging[A](action: Action[A])= Action.async(action.parser) { request =&gt; Logger.info(&quot;Calling action&quot;) action(request)} 可以使用 composeAction 方法将 Action 混合到 action builders 中 123456class LoggingAction @Inject() (parser: BodyParsers.Default)(implicit ec: ExecutionContext) extends ActionBuilderImpl(parser) { override def invokeBlock[A](request: Request[A], block: (Request[A]) =&gt; Future[Result]) = { block(request) } override def composeAction[A](action: Action[A]) = new Logging(action)} 通过这样 code 后使用，效果和之前的例子一样 123def index = loggingAction { Ok(&quot;Hello World&quot;)} 我们也可以在不使用 action builder 的情况下将 action 混合到 wrapping actions 中 12345def index = Logging { Action { Ok(&quot;Hello World&quot;) }} More complicated actions 更复杂的 Action 到目前为止，我们只展示了完全不会影响请求的 actions。当然，我们也可以对传入的请求对象进行读取和修改。 123456789101112import play.api.mvc._import play.api.mvc.request.RemoteConnectiondef xForwardedFor[A](action: Action[A]) = Action.async(action.parser) { request =&gt; val newRequest = request.headers.get(&quot;X-Forwarded-For&quot;) match { case None =&gt; request case Some(xff) =&gt; val xffConnection = RemoteConnection(xff, request.connection.secure, None) request.withConnection(xffConnection) } action(newRequest)} Note: Play already has built in support for X-Forwarded-For headers. 我们可以 block 请求 12345678910import play.api.mvc._import play.api.mvc.Results._def onlyHttps[A](action: Action[A]) = Action.async(action.parser) { request =&gt; request.headers.get(&quot;X-Forwarded-Proto&quot;).collect { case &quot;https&quot; =&gt; action(request) } getOrElse { Future.successful(Forbidden(&quot;Only HTTPS requests allowed&quot;)) }} 最后我们还能修改返回的结果 12345import play.api.mvc._def addUaHeader[A](action: Action[A]) = Action.async(action.parser) { request =&gt; action(request).map(_.withHeaders(&quot;X-UA-Compatible&quot; -&gt; &quot;Chrome=1&quot;))} Different request types 不同的请求类型 虽然 action composition 允许您在 HTTP request 和 response 级别执行额外的处理，但是您通常希望构建数据转换管道( pipelines)，以便向请求本身添加上下文(context) 或 执行验证(perfom validation)。 ActionFunction 可以看作是作用在 request 上的一个函数，在输入请求类型和传递到下一层的输出类型上都参数化。 每个操作函数都可以表示模块处理，例如身份验证、对象的数据库查找、权限检查或希望跨操作组合和重用的其他操作。 一些实现了实现 ActionFunction 的预定义的 trait 对于不同类型的处理非常有用。 ActionTransformer can change the request, for example by adding additional information. 可以改变一个请求，例如为此请求添加额外信息等。 ActionFilter can selectively intercept requests, for example to produce errors, without changing the request value. 可以选择性的拦截请求，例如在不改变请求的前提下产生一个错误。 ActionRefiner is the general case of both of the above. 上面两个 trait 的通用父类(trait)。 ActionBuilder is the special case of functions that take Request as input, and thus can build actions. 以 “Request“ 作为输入的函数的一种特殊情况，并且是否可以构建 actions。 123456789101112131415161718192021222324252627282930313233343536373839trait ActionRefiner[-R[_], +P[_]] extends ActionFunction[R, P] { /** * 确定怎么处理一个请求，这是继承 ActionRefiner 后需要实现的主方法。 * * 它可以决定立即拦截请求并返回结果(Left)，或者继续处理类型为P的新参数(Right)。 * * @return Either a result or a new parameter to pass to the Action block */ protected def refine[A](request: R[A]): Future[Either[Result, P[A]]] final def invokeBlock[A](request: R[A], block: P[A] =&gt; Future[Result]) = refine(request).flatMap(_.fold(Future.successful, block))(executionContext)}trait ActionFilter[R[_]] extends ActionRefiner[R, R] { /** * 确定是否处理请求。这是 ActionFilter 必须实现的主要方法 * * 它可以决定立即拦截请求并返回结果(Some)，或者继续处理(None)。 * * @return An optional Result with which to abort the request */ protected def filter[A](request: R[A]): Future[Option[Result]] final protected def refine[A](request: R[A]) = filter(request).map(_.toLeft(request))(executionContext)}trait ActionTransformer[-R[_], +P[_]] extends ActionRefiner[R, P] { /** *扩展或转换现有请求。这是ActionTransformer必须实现的主要方法 * @return The new parameter to pass to the Action block */ protected def transform[A](request: R[A]): Future[P[A]] final def refine[A](request: R[A]) = transform(request).map(Right(_))(executionContext)} 我们还可以通过实现 invokeBlock 方法定义自己的 ActionFunction。这样通常可以方便地创建请求的输入和输出类型实例(使用 WrappedRequest)，但这并不是严格必需的。 Authentication action functions 最常见的用例之一是身份验证。我们可以很容易地实现我们自己的身份验证操作转换器，它从原始请求确定用户并将其添加到新的 UserRequest。注意，这也是一个 ActionBuilder，因为它接受一个简单的请求作为输入 12345678910import play.api.mvc._class UserRequest[A](val username: Option[String], request: Request[A]) extends WrappedRequest[A](request)class UserAction @Inject()(val parser: BodyParsers.Default)(implicit val executionContext: ExecutionContext) extends ActionBuilder[UserRequest, AnyContent] with ActionTransformer[Request, UserRequest] { def transform[A](request: Request[A]) = Future.successful { new UserRequest(request.session.get(&quot;username&quot;), request) }} 内置的 authentication action builder 只是一个方便的帮助程序，它可以最小化实现简单情况下身份验证所需的代码，其实现与上面的示例非常相似。 由于编写自己的身份验证帮助程序很简单，所以如果内置的帮助程序不适合您的需要，我们建议这样做。","link":"/p/beeb0951.html"},{"title":"从示例逐渐理解Scala隐式转换","text":"隐式转换和隐式参数是 Scala 的两个功能强大的工具。隐式转换可以丰富现有类的功能，隐式对象是如何被自动呼出以用于执行转换或其他任务的。利用这两点，我们可以提供优雅的类库。 本文将通过几个示例代码来整体学习一下 Scala 隐式转换的四个特性和运用。它们分别是 隐式函数运用、隐式类扩展运用、隐式参数、类型类(Type class)\b运用。 隐式转换 implicit conversion function：指的是那种以 implicit 关键字声明的带有单个参数的函数。这样的函数将被自动应用，将值从一种类型转换为另一种类型。 隐式函数 implicit def定义一个 case class 类 Multiply，并定义一个方法 multiply ，接收一个当前对象，并将值相乘后返回。定义隐式转换函数 int2Multiply 12345678910case class Multiply(m: Int, n: Int) { def multiply(other: Multiply): Multiply = { Multiply(other.m * m, other.n * n) }}object MultiplyImplicit { //定义隐式转换函数，参数单个，将 int 隐式转换为 Multiply 对象 implicit def int2Multiply(n: Int): Multiply = Multiply(n, 2)} 测试类 MultiplyMain 123456789object MultiplyMain { //导入隐式转换方法（局部引用可以避免不想要的隐式转换发生） import com.maple.implic.one.MultiplyImplicit._ def main(args: Array[String]): Unit = { val x: Multiply = 3.multiply(Multiply(2, 1)) println(x.toString) }} 运行程序结果如下:12345结果为：Multiply(6,2)//计算过程，3 隐式转换为 Multiply(3, 2)3 =&gt; Multiply(3, 2)//调用multiply计算Multiply(3, 2).multiply(Multiply(2, 1)) =Multiply( 3*2 , 2*1 ) 如果我们提供多个隐式转换函数12345object MultiplyImplicit { implicit def int2Multiply(n: Int): Multiply = Multiply(n, 2) //提供第二个隐式转换函数 implicit def int2Multiply2(n: Int): Multiply = Multiply(n, 3)} 在 Main 中，我们可以通过两种方式进行指定具体使用哪个隐式转换函数。比如我们选择使用 int2Multiply的隐式转换1234567891011object MultiplyMain { //方法1: 排除 int2Multiply2 方法，引入其余所有的方法 import com.maple.implic.one.MultiplyImplicit.{int2Multiply2 ⇒ _, _} // 方法2: 精确引入 import com.maple.implic.one.MultiplyImplicit.int2Multiply def main(args: Array[String]): Unit = { val x: Multiply = 3.multiply(Multiply(2, 1)) println(x.toString) }} 隐式类，丰富现有类库功能 你是否希望某个类拥有新的方法，而此方法该类并没有提供，那么隐式转换可以丰富这个类，给它提供更多的方法 例如数据库连接类 Connection, 我们希望给它新增一个 executeUpdate 方法来对数据进行修改，例子如下: 123456789101112131415package com.maple.implic.twoimport java.sql.Connectionimport scala.language.implicitConversions//隐式类，Rich表示对Connection的增强类class RichConnection(conn: Connection) { //定义的新方法 executeUpdate，对数据操作 def executeUpdate(sql: String): Int = { conn.prepareStatement(sql).executeUpdate() }}//提供隐式转换 func 来将原有类型转换为Rich 类型object RichConnection { implicit def executeUpdate(connection: Connection) = new RichConnection(connection)} 测试程序 12345678910111213141516171819object ConnectionMain { //引入隐式转换 func import com.maple.implic.two.RichConnection._ def main(args: Array[String]): Unit = { //定义 dataSource val ds: DataSource = { val ds = new MysqlDataSource ds.setURL(&quot;jdbc:mysql://127.0.0.1:3306/maple?useUnicode=true&amp;characterEncoding=utf8&quot;) ds.setUser(&quot;root&quot;) ds.setPassword(&quot;123456&quot;) ds } //获取 conn val connection = ds.getConnection //执行查询 connection.executeUpdate(&quot;UPDATE t_user SET name = 'maple' WHERE id = 1&quot;) }} 上面通过定义一个 RichConnection 我们可以增强现有类 Connection 的功能。这样一来，通过 connection 对数据库进行增删改查，可以简化大量代码。 隐式参数 函数或方法可以带有一个标记为 implicit 的参数列表。在这种情况下，编译器将会查找默认值，提供给本次函数调用。 利用隐式参数进行隐式转换 隐式的函数参数也可以被用作隐式转换。如果我们定义一个泛型函数 1def larger[T](x: T, y: T) = if (x &gt; y) x else y 关于隐式参数的另一件事是，它们可能最常用于提供有关在早期参数列表中显式提到的类型的信息，类似于Haskell的类型类。作为示例，请考虑清单21.2中所示的maxListUpBound函数，该函数返回传递列表的最大元素 1234567891011def maxListUpBound[T &lt;: Ordered[T]](elements: List[T]): T = { elements match { case List() =&gt; throw new IllegalArgumentException(&quot;empty list!&quot;) case List(x) =&gt; x case x :: rest =&gt; val maxRest = maxListUpBound(rest) if (x &gt; maxRest) x else maxRest }} maxListUpBound 表示传入一个 List，然后返回 list 中最大的一个元素。功能简单，但是用法十分限制，该List中的成员必须是 Ordered[T] 的子类，否则就会报错。比如我们运行如下例子 1234567object ImplicitParameterMain { import com.maple.implic.three.ImplicitParameter._ def main(args: Array[String]): Unit = { val result = maxListUpBound(List[Integer](1, 2, 3)) println(result) }} 当我们运行 main 函数时，编译器会报如下错。意思是 Int 不是 Ordered[T] 子类，因此无法使用。 123456Error:(49, 18) inferred type arguments [Int] do not conform to method maxListUpBound's type parameter bounds [T &lt;: Ordered[T]] val result = maxListUpBound(List[Int](1, 2, 3))Error:(49, 42) type mismatch; found : List[Int] required: List[T] val result = maxListUpBound(List[Int](1, 2, 3)) 使用隐式参数优化 如果让 maxListUpBound 更通用，我们需要分离这个函数，增加一个参数，来将 T 转换为 Ordered[T]，使用隐式参数 implicit orders: T ⇒ Ordered[T]来做到这一点。 1234567891011def maxListUpBound2[T](elements: List[T])(implicit orders: T ⇒ Ordered[T]): T = { elements match { case List() =&gt; throw new IllegalArgumentException(&quot;empty list!&quot;) case List(x) =&gt; x case x :: rest =&gt; val maxRest = maxListUpBound2(rest) if (x &gt; maxRest) x else maxRest } } 测试程序： 123456import com.maple.implic.three.ImplicitParameter._def main(args: Array[String]): Unit = { val result = maxListUpBound2(List[Int](1, 2, 3)) println(result)} 结果为3，并没有报错。这其中编译器是将 Int 转换为了 Ordered[Int] 类型类(type class) 让某个类拥有某个算法，我们无需修改这个类，提供一个隐式转换即可。这种做法相对于面向对象的继承扩展来的更灵活。 看下面两个例子，Ordering 是 Scala 提供的类型类 123456789101112131415object Implicits { implicit class OrderedExt[T: Ordering](v: T) { def between(min: T, max: T) = { val ordering = implicitly[Ordering[T]] ordering.lteq(min, v) &amp;&amp; ordering.lteq(v, max) } } implicit class OrderedExt2[T](v: T)(implicit ordering: Ordering[T]) { def between2(min: T, max: T) = { ordering.lteq(min, v) &amp;&amp; ordering.lteq(v, max) } }} 使用，上面两种写法都可以达到相同的功能。 1234567import com.maple.implic.Implicits._def main(args: Array[String]): Unit = { val isBetween = 10.between(2, 20) val isBetween2 = 30.between2(2, 20) println(isBetween) println(isBetween2)} Ordering 这样的特质(trait) 被称为类型类(type class，源自 Haskell) 。类型类定义了某种行为，任何类型都可以通过提供相应的行为来加入这个类。这个类是因为共用的目的而组合在一起的类型。 自定义类型类 Scala 标准类库提供了不少类型类。比如 Equiv、Numeric、Fractional、Hashing、IsTraverableOne、IsTraverableLike 等。我们通过自定义一个类型 CustomOperation 来更深入的学习。 定义特质 CustomOperation 123456trait CustomOperation[T] { // 加操作 def plus(x: T, y: T): T // 乘操作 def multiply(x: T, y: T): T} 在伴生对象中给 String 类型扩展基于 CustomOperation 的功能。 1234567891011121314151617181920212223242526272829object CustomOperation { implicit object StringCustomOperation extends CustomOperation[String] { override def plus(x: String, y: String): String = x + y override def multiply(x: String, y: String): String = x + &quot;*&quot; + y } //定义隐式类,对 `String` 进行增强 implicit class CustomImplicitClass[T: CustomOperation](v: T) { def multiply(x: T, y: T): T = { //从冥界召唤的CustomOperation[T]隐式类型。 val custom = implicitly[CustomOperation[T]] custom.multiply(v, x) + &quot;+&quot; + custom.multiply(v, y).toString } //另外一种写法 /* def multiply(x: T, y: T)(implicit custom: CustomOperation[T]): String = { custom.multiply(v, x) + custom.multiply(v, y).toString }*/ def plus(x: T, y: T): String = { val custom = implicitly[CustomOperation[T]] custom.plus(v, x) + custom.plus(v, y).toString // custom.plus(x, y) } }} 测试类 CustomOperationMain: 12345678import com.maple.implic.typeclass.CustomOperation._object CustomOperationMain { // def main(args: Array[String]): Unit = { val str: String = &quot;maple&quot;.plus(&quot;&lt;&quot;, &quot;&gt;&quot;) println(str) }} 结果如下: 1234maple&lt;maple&gt;//隐式转换的运算过程为 custom.plus(v, x) + custom.plus(v, y).toString override def plus(x: String, y: String): String = x + y 如果想要对 Double 支持上述操作，同样定义如下类型类扩展即可： 12345implicit object DoubleCustomOperation extends CustomOperation[Double] { override def plus(x: Double, y: Double): Double = x + y override def multiply(x: Double, y: Double): Double = x * y } 测试用例： 12345import com.maple.implic.typeclass.CustomOperation._def main(args: Array[String]): Unit = { val doubleValue = 5.5.multiply(2.0, 3.0) println(doubleValue)} 结果为 11.0+16.5计算过程： 1234custom.multiply(v, x) + &quot;+&quot; + custom.multiply(v, y).toStringoverride def multiply(x: Double, y: Double): Double = x * y//相乘后字符串相加5.5*2.0 + 5.5*3.0 ===&gt; 11.0+16.5 Type Class 总结TypeClass 将 行为定义 与 具有行为的对象 分离。有点类似于 AOP，但是比 AOP 简洁很多。同时, 在函数式编程中，通常将 数据 与 行为 相分离，甚至是数据与行为按需绑定，已达到更为高级的组合特性。 隐式转换触发时机Scala 会考虑如下的隐式转换函数： 1.位于源或目标类型的伴生对象中的隐式函数或隐式类。 2.位于当前作用域中可以以单个标识符指代的隐式函数或隐式类。隐式转换可以显示加上，来进行代码调试。 总结本文主要介绍 Scala 隐式转换的几种用法，通过详细的例子加深读者对隐式转换的理解。关于隐式转换的触发时机以及编译器优化顺序等，将不在本篇文章详细介绍，可以关注笔者后续文章。 推荐最后推荐一下本人微信公众号，欢迎大家关注。","link":"/p/2ed76eda.html"},{"title":"🎮 Play 入门与学习(三) Asynchronous results","text":"本章我们将讲解使用 Play 进行异步非阻塞编程情况下，如何处理异步返回结果的问题。 Handling asynchronous results 从现在开始我们将进入异步 http 编程模块，本章将会介绍如何处理异步返回结果。 Make controllers asynchronous 使 controllers 变为异步的 在 Play Framework 内部，其机制是自底向上全异步编程模式的，Play 会以异步、非阻塞的方式处理每个请求。 默认配置(configuration) 针对异步控制器(asynchronous controllers) 进行了优化。换句话说，应用程序代码应该尽量避免在控制器中进行阻塞,这样会导致控制器一直等待那个阻塞的操作。此类阻塞操作的常见示例有JDBC调用、流API、HTTP请求和长计算等。 虽然可以增加默认 executionContext 中线程的数量，以允许阻塞控制器处理更多的并发请求，但是遵循建议的保持控制器异步的方法可以更容易地进行扩展，并在负载下保持系统响应。 Creating non-blocking actions 创建非阻塞的 actions 由于 Play 的工作方式，action 代码必须尽可能快，即非阻塞。那么，如果我们在还没有生成结果情形下，如何返回结果呢?答案是使用 Future。 A Future[Result] will eventually be redeemed with a value of type Result. By giving a Future[Result] instead of a normal Result, we are able to quickly generate the result without blocking. Play will then serve the result as soon as the promise is redeemed. The web client will be blocked while waiting for the response, but nothing will be blocked on the server, and server resources can be used to serve other clients. Using a Future is only half of the picture though! 然而，使用Future只是这幅画的一半. (使用 Future 只是 Play 异步编程的一半) If you are calling out to a blocking API such as JDBC,then you still will need to have your ExecutionStage(执行阶段) run with a different executor, to move it off Play’s rendering thread pool. You can do this by creating a subclass of play.api.libs.concurrent.CustomExecutionContextwith a reference to the custom dispatcher. 这里意思是如果针对长时间阻塞的任务，比如JDBC，像上述方式操作，我们只不过是把当前任务的执行放到了另外一条线程中继续阻塞了而已，因此仍然是假异步。这时候，我们可以定义自定义的CustomExecutionContext 1234567891011121314151617import play.api.libs.concurrent.CustomExecutionContext//请确保使用&quot;Scala Dependency Injection&quot;文档页面中列出的 custom binding 技术之一//将 new context 绑定到当前 trait trait MyExecutionContext extends ExecutionContextclass MyExecutionContextImpl @Inject()(system: ActorSystem) extends CustomExecutionContext(system, &quot;my.executor&quot;) with MyExecutionContextclass HomeController @Inject()(myExecutionContext: MyExecutionContext, val controllerComponents: ControllerComponents) extends BaseController { def index = Action.async { Future { // Call some blocking API Ok(&quot;result of blocking call&quot;) }(myExecutionContext) }} How to create a Future[Result] 要创建一个 Future[Result]，我们首先需要另一个future, 这个 future 会给我们返回我们需要计算的实际的结果。 1234val futurePIValue: Future[Double] = computePIAsynchronously()val futureResult: Future[Result] = futurePIValue.map { pi =&gt; Ok(&quot;PI value computed: &quot; + pi)} All of Play’s asynchronous API calls give you a Future. This is the case whether you are calling an external web service using the play.api.libs.WS API, or using Akka to schedule asynchronous tasks or to communicate with actors using play.api.libs.Akka. PlayFramework 所有异步的 API 返回的结果都是一个 Future，无论你是通过 play.api.libs.WS API 调用一个外部的 web 服务，或者使用Akka调度异步任务，或者使用 play. API .lib .Akka与 actor 通信等等，返回都是 Future。 下面是一个通过异步模式执行一段阻塞的代码，并返回一个 Future 简单的例子 123val futureInt: Future[Int] = scala.concurrent.Future { intensiveComputation()} 注意点It’s important to understand which thread code runs on with futures. In the two code blocks above, there is an import on Plays default execution context. This is an implicit parameter that gets passed to all methods on the future API that accept callbacks. The execution context will often be equivalent to a thread pool, though not necessarily. 理解哪些线程代码在 Future 上运行是很重要的。在上面的两个代码块中，在 Play 默认 executionContext 上有一个导入。这是一个隐式参数，传递给 future API上所有接受回调的方法。executionContext 通常等价于线程池，但也不一定。 You can’t magically turn synchronous IO into asynchronous by wrapping it in a Future. If you can’t change the application’s architecture to avoid blocking operations, at some point that operation will have to be executed, and that thread is going to block. So in addition to enclosing the operation in a Future, it’s necessary to configure it to run in a separate execution context that has been configured with enough threads to deal with the expected concurrency. See Understanding Play thread pools for more information, and download the play example templates that show database integration. 你不能通过将代码块包装在一个 Future下来神奇地把同步IO变成异步的。如果您不能更改应用程序的体系结构以避免阻塞操作，那么在某个时刻，该操作将不得不执行，而该线程将阻塞。 因此，除了将操作封装在 Future 中之外，还需要将其配置为在一个单独的 executionContext 中运行，该上下文中已经配置了足够的线程来处理预期的并发。有关更多信息，请参见了解Play线程池，并下载显示数据库集成的Play示例模板 It can also be helpful to use Actors for blocking operations. Actors provide a clean model for handling timeouts and failures, setting up blocking execution contexts, and managing any state that may be associated with the service. Also Actors provide patterns like ScatterGatherFirstCompletedRouter to address simultaneous cache and database requests and allow remote execution on a cluster of backend servers. But an Actor may be overkill depending on what you need. 对于阻塞操作场景，使用 Actors 模式是一个不错的选择。Actors 提供了一个简单一个简单的模型，来处理超时、故障、设置阻塞的 executionContext 以及与服务关联的任何状态。 Actors 还提供了像 “ScatterGatherFirstCompletedRouter” 这样的模式来处理同步缓存和数据库请求，并允许在后端服务器集群上远程执行。但是一个 actor 可能会因为你的需要而 overkill。 Returning futures 返回 futures While we were using the Action.apply builder method to build actions until now, to send an asynchronous result we need to use the Action.async builder method: 当我们使用 Action.apply 时，将 builder 方法应用于 actions ，到目前为止，要发送异步结果，我们需要使用异步的 Actiton builder 方法 1234def index = Action.async { val futureInt = scala.concurrent.Future { intensiveComputation() } futureInt.map(i =&gt; Ok(&quot;Got result: &quot; + i))} Actions are asynchronous by default 默认情况下，Actions 是异步的。例如，在下面的控制器代码中，代码的{Ok(…)} 部分不是控制器的方法体。它是一个匿名函数，被传递给 Action 对象的 apply方法，该方法创建一个 Action 类型的对象。在内部，您编写的匿名函数将被调用，其结果将返回在 Future中。 123def echo = Action { request =&gt; Ok(&quot;Got request [&quot; + request + &quot;]&quot;)} Note: Both Action.apply and Action.async create Action objects that are handled internally in the same way. There is a single kind of Action, which is asynchronous, and not two kinds (a synchronous one and an asynchronous one). The .async builder is just a facility to simplify creating actions based on APIs that return a Future, which makes it easier to write non-blocking code. 注意Action.apply 和 Action.async 在内部都以相同的方式来处理 Action 对象。 有一种单独的 Action，它是异步的，但是不是a synchronous one and an asynchronous one 中的一种。 .async builder只是一个工具，用于在创建 actions 时基于返回 Future result 的 api 的操作进行简化，这使得编写非阻塞代码更加容易。 Handling time-outs 处理超时情况 正确处理超时，避免 web 浏览器阻塞并在出现问题时等待，这通常很有用。您可以使用 play.api.libs.concurrent.Futures 来将非阻塞的超时包装在一个 Futures 中 123456789101112import scala.concurrent.duration._import play.api.libs.concurrent.Futures._def index = Action.async { // 你可以隐式的提供一个超时参数，这题哦你歌唱可以通过controller的构造参数来达到。 intensiveComputation().withTimeout(1.seconds).map { i =&gt; Ok(&quot;Got result: &quot; + i) }.recover { case e: scala.concurrent.TimeoutException =&gt; InternalServerError(&quot;timeout&quot;) }} 注意超时(Timeout)与取消(cancellation) 是不同的。对于超时而言，即使出现了超时，给定的 Future 仍然会完成，即使未返回已完成的值。","link":"/p/fe729f21.html"},{"title":"RocketMQ(一):环境搭建","text":"RocketMQ 是一款分布式、队列模型的消息中间件，具有以下特点：能够保证严格的消息顺序,提供丰富的消息拉取模式,高效的订阅者水平扩展能力,实时的消息订阅机制,亿级消息堆积能力, 前置知识 ssh工具连接linux工具SecureCRT 颜色设置,参考 中文乱码，参考 Linux相关知识centos7 防火墙firewalld的基本使用,参考 启动： systemctl start firewalld 查看状态： systemctl status firewalld 停止： systemctl disable firewalld 禁用： systemctl stop firewalld 配置firewalld-cmd 查看版本： firewall-cmd --version 查看帮助： firewall-cmd --help 显示状态： firewall-cmd --state 查看所有打开的端口： firewall-cmd --zone=public --list-ports 更新防火墙规则： firewall-cmd --reload 查看区域信息: firewall-cmd --get-active-zones 查看指定接口所属区域： firewall-cmd --get-zone-of-interface=eth0 拒绝所有包：firewall-cmd --panic-on 取消拒绝状态： firewall-cmd --panic-off 查看是否拒绝： firewall-cmd --query-panic 开启一个对外端口步骤 先查看是否开启，查看所有打开的端口: firewall-cmd --zone=public --list-ports 添加:firewall-cmd --zone=public --add-port=80/tcp --permanent(–permanent永久生效，没有此参数重启后失效) 1234//命令含义：–zone #作用域–add-port=80/tcp #添加端口，格式为：端口/通讯协议–permanent #永久生效，没有此参数重启后失效 重新载入: firewall-cmd --reload 查看是否开启: firewall-cmd --zone=public --query-port=80/tcp 删除: firewall-cmd --zone= public --remove-port=80/tcp --permanent 服务器环境(针对2m-noslave) 序号 | IP | 用户名 | 密码 | 角色 | 模式—|—|—|—|—|—|—|—1 | 192.168.100.24| root| | nameServer1,brokerServer1|Master12 | 192.168.100.25| root| | nameServer2,brokerServer2|Master2 Hosts添加信息修改host，做集群的通讯(两台机器都修改) 12vim /etc/hosts IP NAME 192.168.100.24 rocketmq-nameserver1 192.168.100.24 rocketmq-master1 192.168.100.25 rocketmq-nameserver2 192.168.100.25 rocketmq-master2 RocketMQ最简单部署 – 单namesrv 单broker 1.jdk安装 rocketmq安装 上传解压上传使用 rz sz插件，进行上传下载 12yum install -y lrzsz 上传命令为rz，下载命令为sz 解压安装123456tar -zxvf alibaba-rocketmq-3.2.6.tar.gz -C /usr/local //解压到指定目录下mv alibaba-rocketmq alibaba-rocketmq-3.2.6 //重命名，带版本号ln -s alibaba-rocketmq-3.2.6 rocketmq //创建软链接、如果不加 -s 就是创建硬链接 创建存储路径12345678mkdir /usr/local/rocketmq/storemkdir /usr/local/rocketmq/store/commitlogmkdir /usr/local/rocketmq/store/consumequeuemkdir /usr/local/rocketmq/store/index 修改RocketMQ配置文件1234vim /usr/local/rocketmq/conf/2m-noslave/broker-a.propertiesvim /usr/local/rocketmq/conf/2m-noslave/broker-b.properties 作为broker启动时的参数配置文件 参考配置123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293#所属集群名字brokerClusterName=rocketmq-cluster#broker名字，注意此处不同的配置文件填写的不一样brokerName=broker-a|broker-b#0 表示 Master，&gt;0 表示 SlavebrokerId=0#nameServer地址，分号分割namesrvAddr=rocketmq-nameserver1:9876;rocketmq-nameserver2:9876#在发送消息时，自动创建服务器不存在的topic，默认创建的队列数defaultTopicQueueNums=4#是否允许 Broker 自动创建Topic，建议线下开启，线上关闭autoCreateTopicEnable=true#是否允许 Broker 自动创建订阅组，建议线下开启，线上关闭autoCreateSubscriptionGroup=true#Broker 对外服务的监听端口listenPort=10911#删除文件时间点，默认凌晨 4点deleteWhen=04#文件保留时间，默认 48 小时fileReservedTime=120#commitLog每个文件的大小默认1GmapedFileSizeCommitLog=1073741824#ConsumeQueue每个文件默认存30W条，根据业务情况调整mapedFileSizeConsumeQueue=300000#destroyMapedFileIntervalForcibly=120000#redeleteHangedFileInterval=120000#检测物理文件磁盘空间diskMaxUsedSpaceRatio=88#存储路径storePathRootDir=/usr/local/rocketmq/store#commitLog 存储路径storePathCommitLog=/usr/local/rocketmq/store/commitlog#消费队列存储路径存储路径storePathConsumeQueue=/usr/local/rocketmq/store/consumequeue#消息索引存储路径storePathIndex=/usr/local/rocketmq/store/index#checkpoint 文件存储路径storeCheckpoint=/usr/local/rocketmq/store/checkpoint#abort 文件存储路径abortFile=/usr/local/rocketmq/store/abort#限制的消息大小maxMessageSize=65536#flushCommitLogLeastPages=4flushConsumeQueueLeastPages=2#flushCommitLogThoroughInterval=10000#flushConsumeQueueThoroughInterval=60000#Broker 的角色#- ASYNC_MASTER 异步复制Master#- SYNC_MASTER 同步双写Master#- SLAVEbrokerRole=ASYNC_MASTER#刷盘方式#- ASYNC_FLUSH 异步刷盘#- SYNC_FLUSH 同步刷盘flushDiskType=ASYNC_FLUSH#checkTransactionMessageEnable=false#发消息线程池数量#sendMessageThreadPoolNums=128#拉消息线程池数量#pullMessageThreadPoolNums=128 修改日志配置文件12 修改启动脚本参数123 上面两步省略，直接上传到linux解压等即可 启动服务namesrv 1.到bin目录下加入执行权限 chmod +x * 2.修改启动的堆内存初始大小1`vim runserver.sh` //更改内存设置 3.启动1./mqnamesrv 4.后台运行进程:12nohup ./mqnamesrv &amp; 5.jps查看进程查看是否成功: tail -f nohup.out 启动服务broker（master）1.修改启动的堆内存初始大小123vim runbroker.sh //更改内存设置 2. 启动12nohup sh mqbroker -n &quot;192.168.1.107:9876&quot; &amp; 3.指定配置文件的方式启动123456nohup sh mqbroker -n &quot;192.168.1.107:9876&quot; -c ../conf/2m-noslave/broker-a.properties &gt; broker.out &amp; nohup sh mqbroker -n &quot;127.0.0.1:9876&quot; -c ../conf/2m-noslave/broker-a.properties &gt; broker.out &amp;nohup sh mqbroker -c /usr/local/rocketmq/conf/2m-noslave/broker-a.properties &gt;/dev/null 2&gt;&amp;1 &amp; 4.使用./mqadmin来观察namesrv和broker的情况1./mqadmin clusterList -n 192.168.1.107:9876 //ip为namesrv地址 查看是否成功启动12345netstat -ntlp# jps# tail -f -n 500 /usr/local/rocketmq/logs/rocketmqlogs/broker.log# tail -f -n 500 /usr/local/rocketmq/logs/rocketmqlogs/namesrv.log 停止Rocketmq123456cd /usr/local/rocketmq/binsh mqshutdown brokersh mqshutdown namesrv 数据清理(停止后进行数据清理)12345678910--等待停止# rm -rf /usr/local/rocketmq/store# mkdir /usr/local/rocketmq/store# mkdir /usr/local/rocketmq/store/commitlog# mkdir /usr/local/rocketmq/store/consumequeue# mkdir /usr/local/rocketmq/store/index--按照上面步骤重启NameServer与BrokerServer 5.RocketMQ需要打开的防火请端口号 9876,10911,10912","link":"/p/86274e11.html"},{"title":"Spring实战  彻底理解FactoryBean","text":"在强调面向接口编程的同时，有一点需要注意:虽然对象可以通过声明接口来避免对特定接口实现类的过度耦合，但总归需要一种方式将声明依赖接口的对象与接口实现类关联起来。否则，只依赖一个不做任何事情的接口是没有任何用处的。 前言假设我们有一个像代码清单4-30所声明的Foo类， 它声明了一个BarInterface依赖。 1234567public class Foo { private BarInterface barInstance; public Foo(){ // 我们应该避免这样做 // instance = new BarInterfaceImpl(); } // ... }} 如果该类是由我们设计并开发的，那么还好说，我们可以通过依赖注入，让容器帮助我们解除接 口与实现类之间的耦合性。但是，有时，我们需要依赖第三方库，需要实例化并使用第三方库中的相 关类，这时，接口与实现类的耦合性需要其他方式来避免。 7通常的做法是通过使用工厂方法(Factory Method)模式，提供一个工厂类来实例化具体的接口 实现类，这样，主体对象只需要依赖工厂类，具体使用的实现类有变更的话，只是变更工厂类，而主 体对象不需要做任何变动。代码清单4-31演示了这种做法。 使用了工厂方法模式的Foo类可能定义1234567public class Foo { private BarInterface barInterface; public Foo(){ barInterface = BarInterfaceFactory.getInstance(); // 或者 barInterface = new BarInterfaceFactory().getInstance(); }} 针对使用工厂方法模式实例化对象的方式，Spring的IoC容器同样提供了对应的集成支持。我们所 要做的，只是将工厂类所返回的具体的接口实现类注入给主体对象(这里是Foo)。","link":"/p/60362379.html"},{"title":"从示例逐渐理解Scala尾递归","text":"1.递归与尾递归1.1 递归1.1.1 递归定义 递归大家都不陌生，一个函数直接或间接的调用它自己本身，就是递归。它通常把一个大型复杂的问题层层转化为一个与原问题相似的规模较小的问题来求解，递归策略只需少量的代码就可以执行多次重复的计算。 1.1.2 递归的条件一般来说，递归需要有边界条件、递归前进段和递归返回段。当边界条件不满足时，递归前进；当边界条件满足时，递归返回。 以递归方式实现阶乘函数的实现： 代码清单1-1 1234def factorial(n:Int): Long ={ if(n &lt;= 0) 1 else n * factorial(n-1)} 代码清单中，if(n &lt;= 0) 1是递归返回段，else后面部分是递归前进段。 1.1.3 递归的缺点： 需要保持调用堆栈,如代码清单1-1,每一次递归都要保存n*factorial(n-1)栈帧信息。如果调用次数太多，可能会导致栈溢出 效率会比较低，递归就是不断的调用自己本身，如果方法本身比较复杂，每次调用自己效率会较低。 1.2 尾递归1.2.1 定义尾递归的定义比较简单，即函数在函数体最后调用它本身，就被称为尾递归。 我们可以这样理解尾递归 所有递归形式的调用都出现在函数的末尾 递归调用是整个函数体中最后执行的语句且它的返回值不属于表达式的一部分 1.2.2 例子程序下面我们使用尾递归的模式实现上面的阶乘代码清单1-2 123456789def factorial(n:Int):Long = { @tailrec def factorial(main:Int,aggr:Int): Long ={ if(main &lt;= 0) aggr else factorial(main-1,main*aggr) } factorial(n,1)} 我们可以比较代码清单1-1和1-21-1中，每次的递归调用都要本身时依赖n这个变量，所以，它只能是个不同的递归。 1-2中，函数factorial每次返回的都是它自己本身，没有依赖任何值。它做的是将main每次减1，将aggr每次乘main，然后将这两个结果作为下一次递归调用的参数，进行调用。 尾递归的核心思想是通过参数来传递每一次的调用结果，达到不压栈。它维护着一个迭代器和一个累加器。 1.3 循环循环能够解决大多数的累计问题，循环可以完成累加和迭代，处理问题比较简单，思想也比较符合，容易理解 n的阶乘循环的写法 代码清单1-3 1234567def fibfor(n:Int): Int ={ var m = 1 for (i &lt;- 1 to n) { m = m * i } m} 循环版本，会有var的可变变量，我们知道，函数式编程就应该更函数范，我们尽可能的要用vals去替换可变的vars所以我们可以使用递归的方式来消除掉vars 2.改写 (循环，递归 TO 尾递归) 事实上，scala都是将尾递归直接编译成循环模式的。所以我们可以大胆的说，所有的循环模式都能改写为尾递归的写法模式 尾递归会维护一个或多个累计值(aggregate)参数和一个迭代参数。我们具体分析 2.1迭代器和累计器 累计值参数aggregate将每次循环产生的结果进行累计，然后传到下一次的调用中。 迭代器，和普通递归或循环一样，每次递归或循环后，改变一次。(如for(i=0;i&lt;1-;i++)里面的i) 2.2 普通递归转换为尾递归 并不是所有的递归都能改写为尾递归，那些比较复杂的递归调用时无法优化为尾递归的。但是大部分还是能够进行优化的。 代码清单1-1 和代码清单 1-2 是求n阶阶乘的普通递归与尾递归的写法，前者没有进行优化，每次调用都会压栈。后者，通过定义一个aggregate(累计)参数，对每一次调用后的结果做一次累计,而另一个参数main称为迭代器,每一次调用都会-1，当达到符合返回的条件时，将累计值返回。 2.3 循环（while loop）转为尾递归（tail recursion） 正如上文循环例子所述，存在var,函数式编程就应该有函数范，我们尽量使用val来代替，所以接下来来看，怎么将循环转换为尾递归 2.3.1 循环和尾递归 正如上文所说的迭代器和累计器，循环和尾递归都有这两个概念 迭代器和累计器 尾递归每一次的调用自身都会有一次累加（或者累积，累减等），然后会有一个迭代器进行迭代，一个累加器进行累加迭代的结果，然后作为参数，再去调用自身。 2.3.2 如上面求n阶乘的尾递归例子： 1.循环的例子中存在一个var，它在每次循环中充当一个累加器的角色，累加每一次的迭代结果，而每次迭代过程就是m*i的一个过程。 2.尾递归也是一样的思想，以main作为迭代器，每次递减1，类似循环里的i，以aggr作为累加器，每次累计迭代的结果，类似循环的m。 3.相对于普通的递归，这里尾递归多的一个参数就是累加器aggr，用于累计每一次递归迭代的结果。这样做的目的就是每一次调用的结果可以作为下一次函数调用的参数。 3.具体示例-加深理解3.1 例子1 - 求斐波拉契数列 普通递归写法（性能较低） 123456def fibonacci(n:Int): Long ={ n match { case 1 | 2 =&gt; 1 case _ =&gt; fibonacci(n-1) + fibonacci(n-2) }} 循环的写法（循环写法） 1234567891011121314def fibonacciFor(n:Int): Int = { var current = 1 var next = 1 if(n &lt;=2) 1 else { for(i &lt;- 2 until n) { var aggr = current + next current = next next = aggr } next }} 可以看到，aggr是累加器，然后将累加的值赋值给下一个next，而current等于next，每一次循环，都有给current和next赋予新值,当累加完成后，返回next的值。 尾递归写法 如何对其进行优化？仔细分析,上面的普通循环，每一轮两个值都在改变，然后又一个累加器aggr，对这两个值进行累加，并赋值给更大的next，然后进入下一次循环。 尾递归，我们也是同样的做法，定义两个接受值，当前的，和下一个，然后需要一个累加值。 这里普通方法的递归调用是两个原函数相加，涉及到的变量有 n , n-1 , n-2因此,我们在考虑使用尾递归时，可能也需要使用到三个参数，初略涉及，尾递归函数需要使用三个参数，于是改写如下： 12345678910111213def fibonacci(n: Int): Long = { @tailrec def fibonacciTail(main: Int, current: Int, next: Int): Long = { main match { case 1 | 2 =&gt; next case _ =&gt; fibonacciByTail(main - 1, next, current+next) } fibonacciTail(n, 1, 1) } fibonacciTail(n,1,1)} 使用尾递归和模式匹配。每一次调用自身，将next赋值给current，然后累加current和next的值赋值给新的next值，call下一轮。思想上和上面循环很像。但是更函数范，消除掉了var。 3.2 例子2 - loadBalance算法 需求，设计一个程序，传入一个比例数组，比如Array（1,3,6,一直调用该函数，返回的3个节点的比例也应该如传入的1:3:6的比例一样。 我最开始使用for循环和return实现了这个需求，代码如下：123456789101112131415161718def loadBalance(arr:Array[Int]): Int ={ //根据传入的数组使用scan高级函数进行变化，具体算法例子： //eg （1，3，6） -&gt; (1,4,10) //这样的目的是，随机出来的值为0-1时，选择第一个节点，为1-4时选择第二节点，依次类推 val segment:Array[Int] = arr.scan(0)(_ + _).drop(1) //随机数的范围，根据传入的数组的数据之和来，例如上的便是 10 ，产生的随机数介于0 - 9 之间 val weightSum:Int = arr.sum val random = new Random().nextInt(weightSum) for(i &lt;- 0 until segment.size ){ if(random &lt; segment(i)){ return i } } 0} 我通过测试程序调用1万次该方法，返回的随机节点的比例是符合传入的比例的。 思考：虽然这样可以达到目的，但是代码写的既不优雅，在scala函数式编程中最好是不能使用return来强行打断函数执行的，并且在最后，我还需要去写一个0来作为默认返回。 尾递归优化 大部分或者几乎所有的for循环都能使用尾递归进行优化，那上面这个代码如何进行优化呢？ 思路：上文的for循环，每次增加的是segment的下标，每循环一次 +1，因此，我们在设计尾递归时，可以使用一个参数来实现相同的功能，而另一个参数应该就是产生的随机数。ok，我们来进行实现 123456789101112131415161718def loadBalance(arr:Array[Int]): Int ={ //根据传入的数组使用scan高级函数进行变化，具体算法例子： //eg （1，3，6） -&gt; (1,4,10) //这样的目的是，随机出来的值为0-1时，选择第一个节点，为1-4时选择第二节点，依次类推 val segment:Array[Int] = arr.scan(0)(_ + _).drop(1) //随机数的范围，根据传入的数组的数据之和来，例如上的便是 10 ，产生的随机数介于0 - 9 之间 val weightSum:Int = arr.sum val random = new Random().nextInt(weightSum) //写一个内部方法 def loadUtil(rand:Int,index:Int) { //assert，保证程序健壮 assert(index &lt; arr.length &amp;&amp; arr(index) &gt;= 0) if(rand &lt; segment(index)) index else loadUtil(rand,index+1) } loadUtil(random,0)} 我们可以看到，使用尾递归的做法，代码会非常的优雅，现在写一个测试类进行测试！ 123456789101112131415161718192021222324def main(args: Array[String]): Unit = { val arr = Array(1,2,7) val countMap = collection.mutable.Map[Int,Int]() for(_ &lt;- 1 until 100000) { val res = loadBalance(arr) countMap.get(res) match { case Some(x) =&gt; countMap += (res -&gt; (x+1)) case None =&gt; countMap +=(res -&gt; 1) } } countMap.foreach(x =&gt; { println(s&quot;${x._1} 调用次数 ${x._2}&quot;) }) }//测试10000次，返回结果如下：2 调用次数 699661 调用次数 200280 调用次数 10005 如上，测试是通过的！是不是很优雅，感受到了尾递归的魅力？ 4. scala编译器对尾递归的优化Scala 对形式上严格的尾递归进行了优化，对于严格的尾递归，不需要注解 @tailrec 可以让编译器去检查该函数到底是不是尾递归，如果不是会报错 具体以上面那个计算斐波拉契数列的例子进行性能分析1234567891011121314151617181920def time[T](t: =&gt;T): T = { val b = System.nanoTime() val x = t val e = System.nanoTime(); println(&quot;time: &quot; + (e-b)/1000 + &quot;us&quot;); x }var count: Long = 0 // @tailrec def fib2(n: Long): Long = { count += 1 n match { case 1 | 2 =&gt; 1 case _ =&gt; fib2(n-1) + fib2(n-2) } } 通过上面时间和调用次数的测试，可以得出尾递归的性能消耗很低，速度很快。 4.1 编译器对尾递归的优化当编译器检测到一个函数调用是尾递归的时候，它就覆盖当前的活动记录而不是在栈中去创建一个新的。 scala编译器会察觉到尾递归，并对其进行优化，将它编译成循环的模式。 4.2 Scala尾递归的限制 尾递归有严格的要求，就是最后一个语句是递归调用，因此写法比较严格。 尾递归最后调用的必须是它本身，间接的赋值它本身的函数也无法进行优化。 5. 总结循环调用都是一个累计器和一个迭代器的作用，同理，尾递归也是如此，它也是通过累加和迭代将结果赋值给新一轮的调用，通过这个思路，我们可以轻松的将循环转换为尾递归的形式。 [本文完，欢迎转载，转载请注明出处]","link":"/p/b2d7d4cd.html"},{"title":"源码解读(一): ThreadLocal工作原理","text":"ThreadLocal为解决并发问题提供了新的思路，能够简洁的编写出优美的多线程程序.当使用ThreadLocal维护变量时，ThreadLocal为每个使用该变量的线程提供独立的变量副本,所以每一个线程都可以独立地改变自己的副本，而不会影响其它线程所对应的副本.从线程的角度看，目标变量就象是线程的本地变量，这也是类名中Local所要表达的意思.所以，在Java中编写线程局部变量的代码相对来说要笨拙一些. ThreadLocal中的方法12345678910111213141516171819202122public class DataSourceTypeManager { private static final ThreadLocal&lt;DataSources&gt; dataSourceTypes = new ThreadLocal&lt;DataSources&gt;() { @Override protected DataSources initialValue() { return DataSources.DATASOURCE_DEFAULT; } }; public static DataSources get() { return dataSourceTypes.get(); } public static void set(DataSources dataSourceType) { dataSourceTypes.set(dataSourceType); } public static void reset() { dataSourceTypes.set(DataSources.DATASOURCE_DEFAULT); }} initialValue(): 返回该线程局部变量的初始值,该方法是protected修饰的，是让子类去进行覆盖的。它是延迟调用的，在线程第1次调用get()或set(Object)时才执行，并且仅执行1次。ThreadLocal中的缺省实现直接返回一个null。 set(Object value): 设置当前线程的线程局部变量的值。 get(): 返回当前线程所对应的线程局部变量。 remove(): 将当前线程局部变量的值删除,目的是为了减少内存的占用，JDK 5.0新增方法。注意，当线程结束后，对应该线程的局部变量将自动被垃圾回收，所以显式调用该方法清除线程的局部变量并不是必须的操作，但可以加快内存回收的速度。 reset(): 在JDK5.0中，ThreadLocal已经支持泛型，该类的类名已经变为ThreadLocal&lt;T&gt;,新版本方法 void set(T value)、T get()和T initialValue()。 如何做到每一个线程维护一个变量副本在ThreadLocal类中有一个Map，用于存储每一个线程的变量副本，Map中元素的键为线程对象，而值对应线程的变量副本。 源码123456789101112131415//get方法实现public T get() { Thread t = Thread.currentThread(); //&lt;1&gt; ThreadLocalMap map = getMap(t); //&lt;2&gt; if (map != null) { ThreadLocalMap.Entry e = map.getEntry(this);//&lt;3&gt; if (e != null) { @SuppressWarnings(&quot;unchecked&quot;) T result = (T)e.value; return result; } } return setInitialValue(); } &lt;1&gt;取得当前线程t &lt;2&gt;通过getMap(t)方法获取到一个map，类型为ThreadLocalMap。 &lt;3&gt;接着通过当前对象作为key获取到&lt;key,value&gt;键值对，注意这里获取键值对传进去的是this，而不是当前线程t。 如果获取成功，则返回value值。 如果map为空，则调用setInitialValue方法返回value。 我们上面的每一句来仔细分析,首先看一下getMap方法中做了什么 1234ThreadLocalMap getMap(Thread t) { return t.threadLocals;} 在getMap中，是调用当前线程t，返回当前线程t中的一个成员变量threadLocals。点进去这个方法，去Thread类中取看一下成员变量threadLocals是什么? 1234/* ThreadLocal values pertaining to this thread. This map is maintained* by the ThreadLocal class. */ThreadLocal.ThreadLocalMap threadLocals = null; 意思是，这个ThreadLocal变量是附属在这个线程中的，这个map是由ThreadLocal去维护的。ThreadLocalMap这个类是ThreadLocal类的一个内部类，继续看ThreadLocalMap的实现： 12345678910111213static class ThreadLocalMap { static class Entry extends WeakReference&lt;ThreadLocal&lt;?&gt;&gt; { /** The value associated with this ThreadLocal. */ Object value; Entry(ThreadLocal&lt;?&gt; k, Object v) { super(k); value = v; }}//...略 可以看到ThreadLocalMap的Entry继承了WeakReference，并且使用ThreadLocal作为Key。继续看setInitialValue方法的具体实现： 12345678910private T setInitialValue() { T value = initialValue(); Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) map.set(this, value); else createMap(t, value); return value; } 根据源码我们可以看到，就是如果map不为空，就设置键值对，为空，再创建Map，看一下createMap的实现： 123456void createMap(Thread t, T firstValue) { t.threadLocals = new ThreadLocalMap(this, firstValue);} 如果为空，直接new了一个ThreadLocalMap,key是ThreadLocal对象 至此，已经明白了ThreadLocal是如何为每个线程创建变量的副本的： 首先，在每个线程Thread内部有一个ThreadLocal.ThreadLocalMap类型的成员变量threadLocals，这个threadLocals就是用来存储实际的变量副本的，键值(key)为当前ThreadLocal变量，value为变量副本（即T类型的变量）。 初始时，在Thread里面，threadLocals为空，当通过ThreadLocal变量调用get()方法或者set()方法，就会对Thread类中的threadLocals进行初始化，并且以当前ThreadLocal变量为键值，以ThreadLocal要保存的副本变量为value，存到threadLocals。 然后在当前线程里面，如果要使用副本变量，就可以通过get方法在threadLocals里面查找。 代码实战下面通过一个例子来证明通过ThreadLocal能达到在每个线程中创建变量副本的效果： 1234567891011121314151617181920212223242526272829303132333435363738394041424344public class Demo3 { private ThreadLocal&lt;Long&gt; longLocal = new ThreadLocal&lt;Long&gt;(); private ThreadLocal&lt;String&gt; stringLocal = new ThreadLocal&lt;String&gt;(); public void set() { longLocal.set(Thread.currentThread().getId()); stringLocal.set(Thread.currentThread().getName()); } public long getLong() { return longLocal.get(); } public String getString() { return stringLocal.get(); } public static void main(String[] args) throws InterruptedException { final Demo3 test = new Demo3(); test.set(); System.out.println(test.getLong()); System.out.println(test.getString()); Thread thread1 = new Thread(){ public void run() { test.set(); System.out.println(test.getLong()); System.out.println(test.getString()); }; }; thread1.start(); thread1.join(); System.out.println(test.getLong()); System.out.println(test.getString()); }} 控制台输出： 1234561 //主线程idmain //主线程名称10 //thread1 idThread-0 //thread1名称1 //主线程idmain //主线程名称 从这段代码的输出结果可以看出，在main线程中和thread1线程中，longLocal保存的副本值和stringLocal保存的副本值都不一样。最后一次在main线程再次打印副本值是为了证明在main线程中和thread1线程中的副本值确实是不同的。(因为当初他们设置值得时候就不会一样的) 总结1）实际上的通过ThreadLocal创建的副本是存储在每个线程自己的threadLocals中的； 2）为何threadLocals的类型ThreadLocalMap的键值为ThreadLocal对象?因为每个线程中可有多个threadLocal变量，就像上面代码实战1中的longLocal和stringLocal； 3）在进行get之前，必须先set，否则会报空指针异常；如果想在get之前不需要调用set就能正常访问的话，必须重写initialValue()方法。因为在上面的代码分析过程中，我们发现如果没有先set的话，即在map中查找不到对应的存储，则会通过调用setInitialValue方法返回i，而在setInitialValue方法中，有一个语句是T value = initialValue()， 而默认情况下，initialValue方法返回的是null。 如代码实战1，我们把set()方法注释掉，运行代码，就会报空指针 1234567//test.set();output:Exception in thread &quot;main&quot; java.lang.NullPointerExceptionat com.may.threadlocal.Demo3.getLong(Demo3.java:14)at com.may.threadlocal.Demo3.main(Demo3.java:26) 但是如果重写了initialValue方法后： 1234567891011121314private ThreadLocal&lt;Long&gt; longLocal = new ThreadLocal&lt;Long&gt;(){ protected Long initialValue() { return Thread.currentThread().getId(); };};private ThreadLocal&lt;String&gt; stringLocal = new ThreadLocal&lt;String&gt;(){ protected String initialValue() { return Thread.currentThread().getName(); }; }; 再去运行，可以正常运行，这样就可以直接不用先set而直接调用get了。建议，一般应用时，重写initialValue()方法，这个方法是延迟调用的，再次强调。 ThreadLocal的应用场景ThreadLocal的应用场合，我觉得最适合的是按线程多实例（每个线程对应一个实例）的对象的访问，并且这个对象很多地方都要用到。最常见的ThreadLocal使用场景为 用来解决 数据库连接、Session管理等。 代码1 12345678910private static ThreadLocal&lt;Connection&gt; connectionHolder= new ThreadLocal&lt;Connection&gt;() { public Connection initialValue() { return DriverManager.getConnection(DB_URL); }}; public static Connection getConnection() { return connectionHolder.get();} 代码2hibernate中典型的ThreadLocal的应用 12345678910111213141516private static final ThreadLocal threadSession = new ThreadLocal(); public static Session getSession() throws InfrastructureException { Session s = (Session) threadSession.get(); try { if (s == null) { s = getSessionFactory().openSession(); threadSession.set(s); } } catch (HibernateException ex) { throw new InfrastructureException(ex); } return s;} 代码3多数据源配置时使用(传送门) 123456789101112131415161718192021public class DataSourceTypeManager { private static final ThreadLocal&lt;DataSources&gt; dataSourceTypes = new ThreadLocal&lt;DataSources&gt;() { @Override protected DataSources initialValue() { return DataSources.DATASOURCE_DEFAULT; } }; public static DataSources get() { return dataSourceTypes.get(); } public static void set(DataSources dataSourceType) { dataSourceTypes.set(dataSourceType); } public static void reset() { dataSourceTypes.set(DataSources.DATASOURCE_DEFAULT); }} 结束语总之，ThreadLocal不是用来解决对象共享访问问题的，而主要是提供了保持对象的方法和避免参数传递的方便的对象访问方式。归纳了两点：1。每个线程中都有一个自己的ThreadLocalMap类对象，可以将线程自己的对象保持到其中，各管各的，线程可以正确的访问到自己的对象。2。将一个共用的ThreadLocal静态实例作为key，将不同对象的引用保存到不同线程的ThreadLocalMap中，然后在线程执行的各处通过这个静态ThreadLocal实例的get()方法取得自己线程保存的那个对象，避免了将这个对象作为参数传递的麻烦。 参考： http://www.iteye.com/topic/103804 http://www.cnblogs.com/dolphin0520/p/3920407.html END","link":"/p/7a285261.html"},{"title":"Spring 学习 [1]","text":"图片测试","link":"/p/ac45747d.html"},{"title":"Scala实战 -- 对List中的部分元素进行合并操作","text":"近期业务出现了一个需求，需要对一个相同实体的List中，部分实体名和id相同的元素进行合并，将其合并为一个实体，以便在业务上做统计处理，合并后的实体为合并前的实体的某些数值相加。此需求催生了本篇文章。我们将抽象一个简单的实体来介绍，如何在Scala List 中合并部分Element 元素。 定义业务实体对象 MergeInfo 定义一个包含 name 和收入数据的实体对象，当判断两个实体的 name 相同时，我们决定对其进行合并操作，将两个实体的 fee 进行累计，完成合并。其中 diff 方法定义了当传入的 target 对象 name 与源对象的 name 相同时，返回 true，否则返回 false。而 merge 操作则是当上一步 diff 返回 true 时，我们会采取的合并操作的具体逻辑。 12345678910111213case class MergeInfo(name: String, fee: Double) { //要比较的目标对象,根据什么条件确定是否需要merge def diff(target: MergeInfo): Boolean = { name == target.name } //定义合并操作 def merge(target: MergeInfo): MergeInfo = { MergeInfo(name, fee + target.fee) }} 使用尾递归遍历 List 并进行合并 实体逻辑定义完成后,我们通过使用尾递归的模式来遍历给定的 List，并使用 matching pattern 模式来进行合并前的判断和合并操作，使用迭代器和累加器将遍历变为尾递归的形式，优化遍历的性能。 使用尾递归模式遍历 List,优化性能。 使用 matching pattern 来判断和合并元素。 使用 隐式转换 特性，使使用此操作变得更为简单和优雅。 1234567891011121314151617181920object Utils { /** * Merging elements in a Scala List */ implicit class ElementMergeOfList(value: List[MergeInfo]) { def merge: List[MergeInfo] = { @tailrec def process(in: List[MergeInfo], accum: List[MergeInfo]): List[MergeInfo] = { in match { case x :: y :: ys if x.diff(y) =&gt; process(x.merge(y) :: ys, accum) case x :: xs =&gt; process(xs, x :: accum) case Nil =&gt; accum } } process(value, Nil).reverse } }} 程序解释： in 输入的源List，待处理和合并。 accum 累加器，每次遍历处理以此List中的元素，并将处理后的元素放入 accu 累加器中 x :: y :: ys 这是Scala语法中对 List组成的一种描述， x，y 均为单个元素，ys 属于尾部，为剩余的 List元素。 测试程序1234567891011121314151617181920212223/*** 将上述隐式转换类引入进来*/object MergeElementSpec { def main(args: Array[String]): Unit = { test1() } def test1(): Unit = { val mergeInfoList = List(MergeInfo(&quot;annual&quot;, 12.5), MergeInfo(&quot;Balance&quot;, 14.3), MergeInfo(&quot;Balance&quot;, 15.7), MergeInfo(&quot;Call&quot;, 21.2), MergeInfo(&quot;Call&quot;, 0.3), MergeInfo(&quot;Date&quot;, 45.4), MergeInfo(&quot;Element&quot;, 24) ) val mergedResult: List[MergeInfo] = mergeInfoList.merge println(s&quot;merge 前元素 size: ${mergeInfoList.size}, merge 后元素 size: ${mergedResult.size}&quot;) println(s&quot;merge 后元素详情: $mergedResult&quot;) }} 运行测试类，结果如下： 1234merge 前元素 size: 7, merge 后元素 size: 5merge 后元素详情：List(MergeInfo(annial,12.5),MergeInfo(Balance,30.0),MergeInfo(Call,12.5),MergeInfo(Date,45.4),MergeInfo(Element,24.0))","link":"/p/a8949b93.html"},{"title":"springmvc 拦截器模板","text":"关键点：’springmvc拦截器 ‘ 需求我们用jquery ajax 请求 后台 用spring 拦截session 过期 1. 过期则跳转指定页面 怎么弄呀2.session的时候 ajax 有时候也会走error 方法 这个怎么写好呢 我们先了解一下一些必要的信息。ajax 请求和普通的 http 请求是不一样的，Ajax请求是XMLHTTPRequest对象发起的，而http请求是浏览器发起的。 二者不同地方体现在HTTP请求的头信息中。 AJAX请求头中带有X-Requested-With信息，其值为XMLHttpRequest。而普通请求是没有的。 在拦截器中进行配置： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception { Oper oper = (Oper)request.getSession().getAttribute(Const.SESSION_LOGIN_ADMIN_USER); String requestCTX = urlPathHelper.getContextPath(request); System.out.println(requestCTX); String requestUri = request.getRequestURI(); //请求完整路径，可用于登陆后跳转 String contextPath = request.getContextPath(); //项目下完整路径 String url = requestUri.substring(contextPath.length()); //请求页面 logger.debug(&quot;======拦截器配置成功======&quot;); logger.debug(&quot;======拦截来自：&quot;+requestUri+&quot;的请求=======&quot;); logger.debug(&quot;======拦截的页面路径是：==：&quot;+url+&quot;=======&quot;); //throw new Exception(&quot;登录超时!&quot;); if(oper == null){//如果获取不到登录的session //如果是ajax请求 if (request.getHeader(&quot;x-requested-with&quot;) != null &amp;&amp; request.getHeader(&quot;x-requested-with&quot;).equalsIgnoreCase(&quot;XMLHttpRequest&quot;)){ response.setHeader(&quot;sessionstatus&quot;, &quot;timeout&quot;); // 响应头设置session状态 return false; //session超时，ajax访问返回false } } return super.preHandle(request, response, handler); } 判断，如果session过期的话，进行上述设置 然后再前端页面主js文件中进行统一设置， 有了配置文件，也有了拦截器，在拦截器中已经设置了返回的信息，而这些信息会被 JavaScript 获取到。 $.ajaxSetup方法是来设置AJAX请求默认选项的， 我们可以认为是全局的选项设置，因此可以将这段代码提到外部js文件中，在需要的页面 test test 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253$.ajaxSetup({ type: 'POST', contentType:&quot;application/x-www-form-urlencoded;charset=utf-8&quot;, complete: function(xhr,status) { var sessionStatus = xhr.getResponseHeader('sessionstatus'); if(sessionStatus == 'timeout') { //var top = getTopWinow(); //var yes = confirm('由于您长时间没有操作, session已过期, 请重新登录.'); //if (yes) { alert(&quot;登录超时,请重新登录！&quot;); window.location.href = '/admin/login/out.do'; //} } } }); /** * 在页面中任何嵌套层次的窗口中获取顶层窗口 * @return 当前页面的顶层窗口对象 */ function getTopWinow(){ var p = window; while(p != p.parent){ p = p.parent; } return p; } 本章完","link":"/p/b935b55.html"},{"title":"使用 Docker 容器方式搭建 Zookeeper 集群","text":"1. Zookeeper是什么Zookeeper 分布式服务框架是 Apache Hadoop 的一个子项目，它主要是用来解决分布式应用中经常遇到的一些数据管理问题，如：统一命名服务、状态同步服务、集群管理、分布式应用配置项的管理等。 Zookeeper 作为一个分布式的服务框架，主要用来解决分布式集群中应用系统的一致性问题，它能提供基于类似于文件系统的目录节点树方式的数据存储， Zookeeper 作用主要是用来维护和监控存储的数据的状态变化，通过监控这些数据状态的变化，从而达到基于数据的集群管理 简单的说，Zookeeper =文件系统+通知机制。 2. Zookeeper集群介绍要搭建一个高可用的 ZooKeeper 集群，我们首先需要确定好集群的规模。为了使得 ZooKeeper 集群能够顺利地选举出 Leader，必须将 ZooKeeper 集群的服务器数部署成奇数。其实任意台 ZooKeeper 服务器都能部署且能正常运行。 一个 ZooKeeper 集群如果要对外提供可用的服务，那么集群中必须要有过半的机器正常工作并且彼此之间能够正常通信。 ZooKeeper 集群有一个特性：过半存活即可用 Zookeeper 的启动过程中 leader 选举是非常重要而且最复杂的一个环节。Zookeeper 的选举过程速度很慢，一旦出现网络隔离，Zookeeper 就要发起选举流程。Zookeeper 的选举流程通常耗时 30 到 120 秒，期间 Zookeeper 由于没有 master，都是不可用的 3. 集群搭建 我们将介绍两种搭建方式，分别在一台机器上启动三个节点使用不同端口号完成伪分布式和在三台节点上完全搭建 Zookeeper 集群。 伪分布式在 docker 容器中搭建 zookeeper 集群，可以用docker-compose.yml 文件 (本教程使用3个容器做集群) 执行 docker-compose up -d 启动容器，启动成功如下图所示： 查看 Zookeeper 节点状态: docker exec -it zoo2 sh 进入容器 ，执行 zkServer.sh status 完全分布式利用 docker-compose 搭建 Zookeeper 集群,本教程使用3个节点，每个节点启动一个 docker 容器做集群，配置和单机节点没啥区别，注意配置 1network_mode: &quot;host&quot; 4. 水平扩容 简单地讲，水平扩容就是向集群中添加更多的机器，以提高系统的服务质量。很遗憾的是，ZooKeeper 在水平扩容扩容方面做得并不十分完美，需要进行整个集群的重启。 通常有两种重启方式，一种是集群整体重启，另外一种是逐台进行服务器的重启。 (1) 整体重启所谓集群整体重启，就是先将整个集群停止，然后更新 ZooKeeper 的配置，然后再次启动。如果在你的系统中，ZooKeeper 并不是个非常核心的组件，并且能够允许短暂的服务停止（通常是几秒钟的时间间隔），那么不妨选择这种方式。在整体重启的过程中，所有该集群的客户端都无法连接上集群。等到集群再次启动，这些客户端就能够自动连接上——注意，整体启动前建立起的客户端会话，并不会因为此次整体重启而失效。也就是说，在整体重启期间花费的时间将不计入会话超时时间的计算中。 (2) 逐台重启这种方式更适合绝大多数的实际场景。在这种方式中，每次仅仅重启集群中的一台机器，然后逐台对整个集群中的机器进行重启操作。这种方式可以在重启期间依然保证集群对外的正常服务。 5. 客户端使用配置 客户端使用 Zookeeper 集群，只需要修改之前的Zookeeper 集群的地址即可 1zookeeper.host=127.0.0.1:2181,127.0.0.1:2182,127.0.0.1:2183","link":"/p/da1f3173.html"},{"title":"🎮 Play 入门与学习(一) Controller &amp; Router &amp; BodyParser","text":"Controllers12345678910111213141516@Singletonclass HomeController @Inject()(cc: ControllerComponents) extends AbstractController(cc) { def index() = Action { implicit request: Request[AnyContent] =&gt; Ok(views.html.index()) } def explore() = Action { implicit request: Request[AnyContent] =&gt; Ok(views.html.explore()) } def tutorial() = Action { implicit request: Request[AnyContent] =&gt; Ok(views.html.tutorial()) } } 在 conf 目录下配置 routes 文件，对请求url 进行映射到 controllers，和 springmvc 的 @RequestMapping 很类似。 123456789# Routes# This file defines all application routes (Higher priority routes first)# https://www.playframework.com/documentation/latest/ScalaRouting# ~~~~# An example controller showing a sample home pageGET / controllers.HomeController.indexGET /explore controllers.HomeController.exploreGET /tutorial controllers.HomeController.tutorial 通过上述配置之后，我们就可以通过 url 访问到具体的 请求方法了。 Action每一个请求是被一个 Action 进行处理了，处理之后返回 Results Results常见的 results 1Ok(&quot;Got request [&quot; + request + &quot;]&quot;) 重定向到另一个 url 对应的 Action 1Redirect(&quot;/echo&quot;) mark 方法还没有完成 1def todo() = TODO 自定义 Result 1234Result( header = ResponseHeader(200, Map.empty), body = HttpEntity.Strict(ByteString(&quot;Hello world!&quot;), Some(&quot;text/plain&quot;))) Http Routing 所有路由信息将定义在 conf/routes 文件下,前文有提及到。router 是负责将每个传入 HTTP 请求转换为 Action 的组件。 每一个 Http 请求被 Play MVC Framework 认为是一个事件。每个请求包含两条主要信息： 请求路径，restful 风格 http 请求方法，类似 Get、Post、Delete、Put 等 语法conf/routes 是 router 使用的配置文件。该文件列出了应用程序所需的所有 routes。每个路由由一个 HTTP 方法和 URI 模式组成，它们都与 Action 的调用相关联。 让我们看看路由定义是什么样的: 12GET /clients/:id controllers.Clients.show(id: Long)GET /clients/:id controllers.Clients.show(id: Long) 通过 -&gt; 来使用不同的路由规则 1-&gt; /api api.MyRouter 当与字符串插值路由DSL(也称为SIRD路由)结合使用时，或者在处理使用多个路由文件路由的子项目时，这一点尤其有用。 通过 nocsrf 来禁用 CSRF filter 12+ nocsrfPOST /api/new controllers.Api.newThing URL规则: 12345678910#静态 pathGET /clients/all controllers.Clients.list()# 动态 pathGET /clients/:id controllers.Clients.show(id: Long)# 正则匹配模式GET /files/*name controllers.Application.download(name) 逆向、反转 routing 1Redirect(routes.HelloController.echo()) 操作处理结果返回结果内容类型自动从您指定作为响应体的Scala值推断出来。 通过 play.api.http.ContentTypeOf 来实现 12345678910//Will automatically set the Content-Type header to text/plain, while:val textResult = Ok(&quot;Hello World!&quot;)//will set the Content-Type header to application/xml.val xmlResult = Ok(&lt;message&gt;Hello World!&lt;/message&gt;)//自己定义返回类型val htmlResult = Ok(&lt;h1&gt;Hello World!&lt;/h1&gt;).as(&quot;text/html&quot;)val htmlResult2 = Ok(&lt;h1&gt;Hello World!&lt;/h1&gt;).as(HTML) Manipulating Http headers (操纵 Http 头)12//添加返回头信息val result = Ok(&quot;Hello World!&quot;).withHeaders(CACHE_CONTROL -&gt; &quot;max-age=3600&quot;,ETAG -&gt; &quot;xx&quot;) Session and Flash 存储在 session 中的数据在整个会话期间都是可用的，存储在 flash 作用域的数据只对下一个请求可用。 需要注意，session 和 flash 的数据不是由服务器存储的，而是使用 cookie 机制添加到每个后续 http 请求中的。这意味着数据大小将非常有限(up to 4kb),并且只能存储字符串值。 cookie 的默认名称是 PLAY_SESSION。这可以在 application.conf 通过配置 key play.http.session 来更改。 Session 存储123456//这会将 session 完全替换掉Ok(&quot;Welcome!&quot;).withSession(&quot;connected&quot; -&gt; &quot;user@gmail.com&quot;)//在现有session 基础上添加 element 内容即可Ok(&quot;Hello World!&quot;).withSession(request.session + (&quot;saidHello&quot; -&gt; &quot;yes&quot;))//通过key remove 部分内容Ok(&quot;Theme reset!&quot;).withSession(request.session - &quot;theme&quot;) 读取 Session 内容 1234567def index = Action { request =&gt; request.session.get(&quot;connected&quot;).map { user =&gt; Ok(&quot;Hello &quot; + user) }.getOrElse { Unauthorized(&quot;Oops, you are not connected&quot;) }} 丢弃整个 Session 内容 1Ok(&quot;Bye&quot;).withNewSession Flash Scope (Flash作用域) flash scope 和 session 作用很像，但是有两个区别 data are kept for only one request the Flash cookie is not signed, making it possible for the user to modify it. session 的 cookie 会进行加密，而 flash 的 cookie 不会进行加密。 Flash作用域 应该只用于在简单的 非ajax 应用程序上传输 成功/错误消息。由于数据只是为下一个请求保存的，而且在复杂的 Web 应用程序中不能保证请求顺序，所以 Flash作用域 受竞态条件的限制。(the Flash scope is subject to race conditions.) code using flash scope123456789def index = Action { implicit request =&gt; Ok { request.flash.get(&quot;success&quot;).getOrElse(&quot;Welcome!&quot;) }}def save = Action { Redirect(&quot;/home&quot;).flashing(&quot;success&quot; -&gt; &quot;The item has been created&quot;)} To retrieve the Flash scope value in your view, add an implicit Flash parameter 要在视图中检索Flash作用域值，请添加一个隐式Flash参数: 1234@()(implicit flash: Flash)...@flash.get(&quot;success&quot;).getOrElse(&quot;Welcome!&quot;)... 请求体解析 Body Parsers 什么是 body parsers HTTP请求 是header 后面跟着 body。header 通常很小——它可以安全地缓冲在内存中，因此在 Play 中它是使用RequestHeader 类建模的。 然而，body 可能非常长，因此不在内存中缓冲，而是建模为流。然而，许多请求体有效负载 (payloads) 都很小，并且可以在内存中建模，因此为了将 body流 映射到内存中的对象，Play 提供了一个BodyParser 抽象。 由于 Play 是一个异步框架，传统的 InputStream 不能用于读取请求体——输入流阻塞了，当您调用 read 时，调用它的线程必须等待数据可用。 相反，Play 使用一个名为 Akka Streams 的异步流库。Akka Streams 是 Reactive Streams 的一个实现。 允许许多异步流api 无缝地协同工作,所以尽管传统 InputStream 的基础技术不适合使用, 但是Akka Streams 和 Reactive Streams 的整个生态系统的异步库将为你提供你需要的一切。 使用 Body Parsers 如果没有显式选择 body parser，Play 将使用的缺省的 body parser 将查看传入的 Content-Type，并相应地解析body。 例如，类型 application/json 的内容类型将被解析为 JsValue，而类型 application/x-www-form- urlencoding 的内容类型将被解析为 Map[String, Seq[String]] 默认的 Body Parser 生成 AnyContent 类型的 Body。AnyContent 支持的各种类型, 可以通过 as方法 访问，例如 asJson，它返回一个 Option[body类型] 1234567891011def save = Action { request: Request[AnyContent] =&gt; val body: AnyContent = request.body val jsonBody: Option[JsValue] = body.asJson // Expecting json body jsonBody.map { json =&gt; Ok(&quot;Got: &quot; + (json \\ &quot;name&quot;).as[String]) }.getOrElse { BadRequest(&quot;Expecting application/json request body&quot;) }} 下面是默认 body parser 支持的类型映射 (The following is a mapping of types supported by the default body parser) text/plain: String, accessible via asText. application/json: JsValue, accessible via asJson. application/xml, text/xml or application/XXX+xml: scala.xml.NodeSeq, accessible via asXml. application/x-www-form-urlencoded: Map[String, Seq[String]], accessible via asFormUrlEncoded. multipart/form-data: MultipartFormData, accessible via asMultipartFormData. Any other content type: RawBuffer, accessible via asRaw. 默认的 body parser 在解析之前会 try to determine 请求是否具有 body。 根据 HTTP 规范(spec)，内容长度(Content-Length) 或 传输编码标头(Transfer-Encoding) 的出现都表示主体的存在，因此解析器只在出现其中一个标头时进行解析，或者在显式设置非空主体时在 FakeRequest 上进行解析。 如果希望在所有情况下解析主体，可以使用下面描述的anyContent主体解析器。 显示的选择一个 Body Parser如果希望显式地选择主体解析器，可以将 body parser 传递给 Action 的 apply或 async 方法。 Play 提供了许多开箱即用的 body parser (Play provides a number of body parsers out of the box)， 这是通过 PlayBodyParsers trait 提供的，它可以注入到您的控制器中。 例子，如果要定义一个 request body 期望是 Json Body 的 Action 1234//如果不是 Json类型会返回 415 Unsupported Media Type , 类似 Springmvc 在参数前面加 @RequestBodydef save = Action(parse.json) { request: Request[JsValue] =&gt; Ok(&quot;Got: &quot; + (request.body \\ &quot;name&quot;).as[String])} 注意，上述 body 的类型为 JsValue, 它不是 Option 类型的了。原因是 json body parser 会验证请求是否具有 application/json 的 Content-Type，如果不是，则会返回 415 的错误，即 415 Unsupported Media Type,这样我们就不用再次检查了。 这样依赖，这个方法将要对请求的type 有严格的限制了，客户端要清楚这一点。如果希望有更宽松的做法，即不是 ``application/json类型的Content-Type` 也能够进行解析，可以使用如下方法： 1234//不会返回 415，会尝试进行解析def save = Action(parse.tolerantJson) { request: Request[JsValue] =&gt; Ok(&quot;Got: &quot; + (request.body \\ &quot;name&quot;).as[String])} 另一个例子，保存文件 123def save = Action(parse.file(to = new File(&quot;/tmp/upload&quot;))) { request: Request[File] =&gt; Ok(&quot;Saved the request content to &quot; + request.body)} 组合 Body Parsers (Combining body parsers)在上一个保存文件的示例中，所有请求 bodies 都存储在同一个文件中 (/tmp/upload)，这是存在问题的。 我们可以编写另一个自定义主体解析器，它从请求会话中提取用户名，为每个用户提供一个惟一的文件 1234567891011val storeInUserFile: BodyParser[File] = parse.using { request =&gt; request.session.get(&quot;username&quot;).map { user =&gt; parse.file(to = new File(&quot;/tmp/&quot; + user + &quot;.upload&quot;)) }.getOrElse { sys.error(&quot;You don't have the right to upload here&quot;) }}//自定义 body parserdef save: Action[File] = Action(storeInUserFile) { request =&gt; Ok(&quot;Saved the request content to &quot; + request.body)} 上面我们并没有真正编写自己的 BodyParser，而只是组合现有的 BodyParser。这通常就足够了，应该涵盖大多数用例。高级主题部分将介绍从头编写 BodyParser Max content length基于文本的 body parsers (例如 text、json、xml 或 formurlencoding) 需要有一个最大内容长度。因为它们必须将所有内容加载到内存中。默认情况下，它们将解析的最大内容长度是 100KB。可以通过指定 play.http.parser 来覆盖它。可以通过在 application.conf 指定 maxMemoryBuffer属性来改变这个大小。 12# application.confplay.http.parser.maxMemoryBuffer=128K 对于将内容缓冲 (buffer) 到磁盘上的 body parser，例如 raw parser 或 multipart/form-data 等，它们的最大内容长度使用 play.http.parser 的 maxDiskBuffer 来进行指定。 maxDiskBuffer属性，默认值为10MB。multipart/form-data 解析器还强制为数据字段的聚合设置文本最大长度属性。 您还可以通过在 Action 中显示指定来覆盖默认的最大长度。 1234// Accept only 10KB of data.def save = Action(parse.text(maxLength = 1024 * 10)) { request: Request[String] =&gt; Ok(&quot;Got: &quot; + text)} You can also wrap any body parser with maxLength 1234// Accept only 10KB of data.def save = Action(parse.maxLength(1024 * 10, storeInUserFile)) { request =&gt; Ok(&quot;Saved the request content to &quot; + request.body)} Writing a custom body parser 我们可以实现 BodyParser 特质来自定义 body parser，这个 trait 是一个很简单的函数 1trait BodyParser[+A] extends (RequestHeader =&gt; Accumulator[ByteString, Either[Result, A]]) 接收一个 RequestHeader，这样我们可以检查关于请求的信息，它通常用于获取 Content-Type,这样 body 就会被正确的解析。 函数的返回类型是 Accumulator，它是一个累加器。Accumulator 是 围绕 Akka Streams Sink 的一层薄层。Accumulator 异步地将 streams of elements 加到结果中，它可以通过传入 Akka Streams Source 来运行。这将返回一个 Future，并且在累加器完成时，future 得到完成。 Accumulator 本质上和 Sink[E,Future[A]] 一样，事实上，Accumulator 是 Sink 的一个包装器。但是最大的区别是 Accumulator 提供了方便的方法，比如 map、mapFuture、recover 等等。 Accumulator 用于将结果作为一个 promise 来处理，其中 Sink 要求将所有的操作包装在 mapMaterializedValue 的调用中。 Accumulator 的 apply 返回 ByteString 类型的元素，这些元素本质上是字节数组，但与 byte[] 不同的是，ByteString 是不可变的，它的许多操作(如 slicing 或者 appending) 都是在固定的时间内完成的。 Accumulator 的返回类型是 Either[Result, A]，它要么返回一个 Result，要么返回一个类型 A。通常在发生错误的情况下返回 Result。例如，如果 body 解析失败，比如 Content-Type 与 Body Parser 接受的类型不匹配，或者内存缓冲区溢出了。当 body parser 返回一个 result 时，这将缩短 action 的处理时间，action 的结果将里脊返回，并且永远不会调用该操作。 将 Body 引向别处 Directing the body elsewhere 编写 body parser 的一个常见用例是，当您实际上不想解析主体时，而是想将它以流的形式引入到其他地方(stream it elsewhere)。为此，您可以定义一个自定义 body parser 12345678910111213141516171819202122import javax.inject._import play.api.mvc._import play.api.libs.streams._import play.api.libs.ws._import scala.concurrent.ExecutionContextimport akka.util.ByteStringclass MyController @Inject() (ws: WSClient, val controllerComponents: ControllerComponents)(implicit ec: ExecutionContext) extends BaseController { def forward(request: WSRequest): BodyParser[WSResponse] = BodyParser { req =&gt; Accumulator.source[ByteString].mapFuture { source =&gt; request .withBody(source) .execute() .map(Right.apply) } } def myAction = Action(forward(ws.url(&quot;https://example.com&quot;))) { req =&gt; Ok(&quot;Uploaded&quot;) }} 使用 Akka Streams 进行自定义的解析 Custom parsing using Akka Streams 在很少的情况下，可能需要使用 Akka Streams 编写自定义解析器。在大多数情况下，先用 ByteString 缓冲 body 就足够了，这通常提供一种简单得多的解析方法，因为您可以对主体使用强制方法和随机访问。 但是，当这不可行时，例如需要解析的主体太长而无法装入内存时，则可能需要编写自定义主体解析器。 关于如何使用 Akka Streams 的完整描述超出了本文档的范围——最好从阅读 Akka Streams 文档开始。但是，下面显示了一个 CSV 解析器，它基于Akka Streams 烹饪书中 ByteStrings 文档流的解析行。 12345678910111213141516171819import play.api.mvc.BodyParserimport play.api.libs.streams._import akka.util.ByteStringimport akka.stream.scaladsl._val csv: BodyParser[Seq[Seq[String]]] = BodyParser { req =&gt; // A flow that splits the stream into CSV lines val sink: Sink[ByteString, Future[Seq[Seq[String]]]] = Flow[ByteString] //我们按照 new line character 进行分割，每行最多允许 1000个字符。 .via(Framing.delimiter(ByteString(&quot;\\n&quot;), 1000, allowTruncation = true)) //把每一行变成一个String，用逗号分隔 .map(_.utf8String.trim.split(&quot;,&quot;).toSeq) // 现在我们使用 fold 将其变为一个列表 List .toMat(Sink.fold(Seq.empty[Seq[String]])(_ :+ _))(Keep.right) // 将 body 转为为 Either right 返回 Accumulator(sink).map(Right.apply)}","link":"/p/468029a2.html"},{"title":"🎮 Play 入门与学习(五) Dependency Injection","text":"依赖注入是一种广泛使用的设计模式，有助于将组件的行为与依赖性解析分开。Play支持基于JSR 330（在本页中描述）的运行时依赖注入和在Scala中编译时依赖注入。之所以调用运行时依赖项注入，是因为依赖关系图是在运行时创建，连接和验证的。 如果找不到特定组件的依赖项，则在运行应用程序之前不会出现错误。 Play支持Guice开箱即用，但可以插入其他JSR 330实现. Guice wiki 是一个很好的资源，可以更多地了解Guice和DI设计模式的功能。 注意：Guice是一个Java库，本文档中的示例使用Guice的内置Java API。 如果您更喜欢Scala DSL，您可能希望使用scala-guice或sse-guice库。 Motivation依赖注入实现了几个目标： 它允许您轻松绑定同一组件的不同实现。 这对于测试尤其有用，您可以使用模拟依赖项手动实例化组件或注入备用实现。 它允许您避免全局静态。 虽然静态工厂可以实现第一个目标，但您必须小心确保正确设置状态。 特别是Play（现已弃用）的静态API需要运行的应用程序，这使得测试的灵活性降低。 并且一次有多个实例可以并行运行测试。 Guice wiki 有一些很好的例子可以更详细地解释这一点。 How it worksPlay 提供了许多内置组件，并在诸如 BuiltinModule 之类的模块中声明它们。 这些绑定描述了创建 Application 实例所需的所有内容，默认情况下包括由 routes compiler 生成的 route，该 route 将控制器注入到构造函数中。 然后可以将这些绑定转换为在 Guice 和其他运行时DI框架中工作。 Play团队维护Guice模块，该模块提供 GuiceApplicationLoader。 这为 Guice 进行绑定转换，使用这些绑定创建Guice注入器，并从注入器请求Application实例。 There are also third-party loaders that do this for other frameworks, including Scaldi and Spring. 或者，Play提供了一个 BuiltInComponents 特性，允许您创建一个纯Scala实现，在编译时将您的应用程序连接在一起。 我们将在下面详细介绍如何自定义默认绑定和应用程序加载器。 Declaring runtime DI dependencies 声明运行时DI依赖项 如果您有一个组件（例如控制器），并且它需要一些其他组件作为依赖项，那么可以使用 @Inject 注解来声明它。 @Inject 注解可用于字段或构造函数。 我们建议您在构造函数上使用它，例如： 123456import javax.inject._import play.api.libs.ws._class MyComponent @Inject() (ws: WSClient) { // ...} 请注意，@Inject 注释必须位于类名之后但在构造函数参数之前，并且必须具有括号。 此外，Guice 确实提供了其他几种类型的注入方式，但构造函数注入通常是 Scala 中最清晰，简洁和可测试的，因此我们建议使用它。 Guice 能够在其构造函数上使用 @Inject 自动实例化任何类，而无需显式绑定它。此功能被称为 just in time bindings，Guice 文档中对此进行了更详细的描述。 如果您需要执行更复杂的操作，可以声明自定义绑定，如下所述。 Dependency injecting controllers 依赖注入控制器 There are two ways to make Play use dependency injected controllers. 有两种方法可以使 Play 使用依赖注入控制器。 Injected routes generator默认情况下（从2.5.0开始），Play 将生成一个 router ，该 router 将声明它所路由的所有控制器作为依赖项，允许您的控制器自己依赖注入。 要专门启用注入的路由生成器，请将以下内容添加到 build.sbt 中的构建设置： 1routesGenerator := InjectedRoutesGenerator 当使用 injected routes generator 时，为操作添加 @ 符号前缀具有特殊含义，这意味着不是直接注入控制器，而是注入控制器的提供者。 例如，这允许 prototype controllers，以及用于打破循环依赖性的选项。 Static routes generator您可以将Play配置为使用 legacy（pre 2.5.0）静态路由生成器，该生成器假定所有操作都是静态方法。 要配置项目，请将以下内容添加到 build.sbt： 1routesGenerator := StaticRoutesGenerator 我们建议始终使用注入的路由生成器。 静态路由生成器主要作为辅助迁移的工具存在，因此现有项目不必一次使所有控制器不是静态的。 如果使用静态路由生成器，则可以通过在操作前加上@来指示操作具有注入的控制器，如下所示： 1GET /some/path @controllers.Application.index Component lifecycle依赖注入系统管理注入组件的生命周期，根据需要创建它们并将它们注入其他组件。以下是组件生命周期的工作原理： 每次需要组件时都会创建新实例。如果组件多次使用，则默认情况下将创建组件的多个实例。如果您只需要组件的单个实例，则需要将其标记为单个实例。 实例在需要时会以懒加载的形式创建。如果组件从未被其他组件使用，则根本不会创建它。这通常是你想要的。对于大多数组件而言，在需要之前创建它们是没有意义的。但是，在某些情况下，您希望直接启动组件，或者即使它们未被其他组件使用也是如此。例如，您可能希望在应用程序启动时向远程系统发送消息或预热缓存。您可以使用急切绑定 (eager binding) 强制创建组件。 除了正常的垃圾收集之外，实例不会自动清理。当组件不再被引用时，它们将被垃圾收集，但框架将不会执行任何特殊操作来关闭组件，例如调用 close 方法。但是，Play 提供了一种特殊类型的组件，称为ApplicationLifecycle，它允许您注册组件以在应用程序停止时关闭。 Singletons有时，您可能拥有一个包含某些状态的组件，例如缓存，或者与外部资源的连接，或者创建组件可能很昂贵。 在这些情况下，该组件应该是单例的。 这可以使用 @Singleton 注解来实现： 123456789import javax.inject._@Singletonclass CurrentSharePrice { @volatile private var price = 0 def set(p: Int) = price = p def get = price} Stopping/cleaning upPlay 关闭时可能需要清理某些组件，例如，停止线程池。 Play提供了一个 ApplicationLifecycle 组件，可用于在 Play 关闭时注册挂钩以停止组件 12345678910111213import scala.concurrent.Futureimport javax.inject._import play.api.inject.ApplicationLifecycle@Singletonclass MessageQueueConnection @Inject() (lifecycle: ApplicationLifecycle) { val connection = connectToMessageQueue() lifecycle.addStopHook { () =&gt; Future.successful(connection.stop()) } //...} ApplicationLifecycle 将在创建时以相反的顺序停止所有组件。 这意味着您依赖的任何组件仍然可以安全地用在组件的停止钩子上。 因为您依赖它们，所以它们必须在组件之前创建，因此在组件停止之前不会停止。 注意：确保注册 stop hook 的所有组件都是单例非常重要。 注册 stop 钩子的任何非单例组件都可能是内存泄漏的来源，因为每次创建组件时都会注册一个新的钩子。 Providing custom bindings 提供自定义绑定 为组件定义 trait 被认为是一种好习惯，并且其他类依赖于该 trait，而不是组件的实现。 通过这样做，您可以注入不同的实现，例如，在测试应用程序时注入模拟实现。 在这种情况下，DI系统需要知道哪个实现应该绑定到该 trait。 我们建议您声明这一点的方式取决于您是将 Play 应用程序编写为 Play 的最终用户，还是编写其他 Play 应用程序将使用的库。 Play applications我们建议 Play 应用程序使用应用程序正在使用的 DI 框架提供的任何机制。 尽管Play确实提供了绑定API，但此API有些限制，并且不允许您充分利用您正在使用的框架的强大功能。 由于Play为Guice提供了开箱即用的支持，下面的示例显示了如何为 Guice 提供绑定。 Binding annotations将实现绑定到接口的最简单方法是使用 Guice @ImplementedBy 注释。 例如： 12345678910import com.google.inject.ImplementedBy@ImplementedBy(classOf[EnglishHello])trait Hello { def sayHello(name: String): String}class EnglishHello extends Hello { def sayHello(name: String) = &quot;Hello &quot; + name} Programmatic bindings在一些更复杂的情况下，您可能希望提供更复杂的绑定，例如当您有一个 trait 的多个实现时，这些 trait 由 @Named 注释限定。 在这些情况下，您可以实现自定义 Guice 模块 123456789101112131415import com.google.inject.AbstractModuleimport com.google.inject.name.Namesclass Module extends AbstractModule { def configure() = { bind(classOf[Hello]) .annotatedWith(Names.named(&quot;en&quot;)) .to(classOf[EnglishHello]) bind(classOf[Hello]) .annotatedWith(Names.named(&quot;de&quot;)) .to(classOf[GermanHello]) }} 如果您将此模块称为 Module 并将其放在根包中，它将自动注册到 Play。 或者，如果要为其指定不同的名称或将其放在不同的包中，可以通过将其全限定名附加到 application.conf 中的 play.modules.enabled 列表来将其注册到 Play 1play.modules.enabled += &quot;modules.HelloModule&quot; 您还可以通过将以下模块添加到已禁用的模块来禁用根软件包中名为 Module 的模块的自动注册 1play.modules.disabled += &quot;Module&quot; Configurable bindings 可配置的绑定 有时您可能希望在配置 Guice 绑定时读取 Play Configuration 或使用 ClassLoader。 您可以通过将这些对象添加到模块的构造函数来访问这些对象。 在下面的示例中，从配置文件中读取每种语言的 Hello 绑定。 这允许通过在 application.conf 文件中添加新设置来添加新的 Hello 绑定。 123456789101112131415161718192021222324252627import com.google.inject.AbstractModuleimport com.google.inject.name.Namesimport play.api.{ Configuration, Environment }class Module(environment: Environment,configuration: Configuration) extends AbstractModule { def configure() = { // Expect configuration like: // hello.en = &quot;myapp.EnglishHello&quot; // hello.de = &quot;myapp.GermanHello&quot; val helloConfiguration: Configuration = configuration.getOptional[Configuration](&quot;hello&quot;).getOrElse(Configuration.empty) val languages: Set[String] = helloConfiguration.subKeys // Iterate through all the languages and bind the // class associated with that language. Use Play's // ClassLoader to load the classes. for (l &lt;- languages) { val bindingClassName: String = helloConfiguration.get[String](l) val bindingClass: Class[_ &lt;: Hello] = environment.classLoader.loadClass(bindingClassName) .asSubclass(classOf[Hello]) bind(classOf[Hello]) .annotatedWith(Names.named(l)) .to(bindingClass) } }} 注意：在大多数情况下，如果在创建组件时需要访问 Configuration，则应将 Configuration 对象注入组件本身或组件的 Provider 中。 然后，您可以在创建组件时读取“配置”。 在为组件创建绑定时，通常不需要读取Configuration。 Eager bindings 提前绑定 在上面的代码中，每次使用时都会创建新的 EnglishHello 和 GermanHello 对象。 如果您只想创建一次这些对象，可能因为创建它们很昂贵，那么您应该使用 @Singleton 注释。 如果你想创建它们一次并在应用程序启动时急切地创建它们，而不是在需要它们懒加载，那么你就可以使用 Guice’s eager singleton binding 1234567891011121314151617import com.google.inject.AbstractModuleimport com.google.inject.name.Names// A Module is needed to register bindingsclass Module extends AbstractModule { override def configure() = { // Bind the `Hello` interface to the `EnglishHello` implementation as eager singleton. bind(classOf[Hello]) .annotatedWith(Names.named(&quot;en&quot;)) .to(classOf[EnglishHello]).asEagerSingleton() bind(classOf[Hello]) .annotatedWith(Names.named(&quot;de&quot;)) .to(classOf[GermanHello]).asEagerSingleton() }} 当应用程序启动时，可以使用 Eager 单例来启动服务。 它们通常与关闭钩子组合在一起，以便服务可以在应用程序停止时清理其资源。 12345678910111213import scala.concurrent.Futureimport javax.inject._import play.api.inject.ApplicationLifecycle// This creates an `ApplicationStart` object once at start-up and registers hook for shut-down.@Singletonclass ApplicationStart @Inject() (lifecycle: ApplicationLifecycle) { // Shut-down hook lifecycle.addStopHook { () =&gt; Future.successful(()) } //...} 1234567import com.google.inject.AbstractModuleclass StartModule extends AbstractModule { override def configure() = { bind(classOf[ApplicationStart]).asEagerSingleton() }} Play libraries如果您正在为Play实现一个库，那么您可能希望它与DI框架无关，这样无论在应用程序中使用哪个DI框架，您的库都可以开箱即用。 出于这个原因，Play提供了一个轻量级绑定API，用于以DI框架无关的方式提供绑定。 要提供绑定，请实现Module以返回要提供的绑定序列。 Module trait还提供用于构建绑定的DSL： 123456789import play.api.inject._class HelloModule extends Module { def bindings(environment: Environment, configuration: Configuration) = Seq( bind[Hello].qualifiedWith(&quot;en&quot;).to[EnglishHello], bind[Hello].qualifiedWith(&quot;de&quot;).to[GermanHello] )} 通过将该模块附加到reference.conf中的play.modules.enabled列表，可以自动注册该模块： 1play.modules.enabled += &quot;com.example.HelloModule&quot; Module bindings方法采用Play环境和配置。 如果要动态配置绑定，可以访问这些。模块绑定支持急切绑定。 要声明一个急切绑定，请在绑定结束时添加.eagerly。 为了最大化跨框架兼容性，请记住以下事项： 并非所有DI框架都只支持时间绑定。 确保明确绑定库提供的所有组件。 尝试保持绑定键简单 - 不同的运行时DI框架对键是什么以及它应该如何唯一或不唯一有不同的看 Excluding modules如果有一个您不想加载的模块，可以通过将其附加到application.conf中的play.modules.disabled属性来将其排除： 1play.modules.disabled += &quot;play.api.db.evolutions.EvolutionsModule&quot; Managing circular dependencies当您的某个组件依赖于依赖于原始组件的另一个组件（直接或间接）时，就会发生循环依赖关系。 例如： 12345import javax.inject.Injectclass Foo @Inject() (bar: Bar)class Bar @Inject() (baz: Baz)class Baz @Inject() (foo: Foo) 在这种情况下，Foo依赖于Bar，它取决于Baz，它依赖于Foo。 因此，您将无法实例化任何这些类。 您可以使用提供程序解决此问题： 12345import javax.inject.{ Inject, Provider }class Foo @Inject() (bar: Bar)class Bar @Inject() (baz: Baz)class Baz @Inject() (foo: Provider[Foo]) 通常，可以通过以更原子的方式分解组件或查找要依赖的更具体的组件来解决循环依赖性。 常见问题是对Application的依赖。 当你的组件依赖于应用程序时，它说它需要一个完整的应用程序来完成它的工作; 通常情况并非如此。 您的依赖项应该位于具有您需要的特定功能的更具体的组件（例如，环境）上。 作为最后的手段，您可以通过注入Provider [Application]来解决问题。 Advanced: Extending the GuiceApplicationLoaderPlay的运行时依赖注入由GuiceApplicationLoader类引导。 该类加载所有模块，将模块提供给Guice，然后使用Guice创建应用程序。 如果要控制Guice如何初始化应用程序，则可以扩展GuiceApplicationLoader类。 您可以覆盖几种方法，但通常需要覆盖构建器方法。 此方法读取ApplicationLoader.Context并创建GuiceApplicationBuilder。 您可以在下面看到构建器的标准实现，您可以按照自己喜欢的方式进行更改。 您可以在有关使用Guice进行测试的部分中找到如何使用GuiceApplicationBuilder。 1234567891011121314import play.api.ApplicationLoaderimport play.api.Configurationimport play.api.inject._import play.api.inject.guice._class CustomApplicationLoader extends GuiceApplicationLoader() { override def builder(context: ApplicationLoader.Context): GuiceApplicationBuilder = { val extra = Configuration(&quot;a&quot; -&gt; 1) initialBuilder .in(context.environment) .loadConfig(extra ++ context.initialConfiguration) .overrides(overrides(context): _*) }} 当您覆盖ApplicationLoader时，您需要告诉Play。 将以下设置添加到application.conf： play.application.loader =“modules.CustomApplicationLoader”您不仅限于使用Guice进行依赖注入。 通过重写ApplicationLoader，您可以控制应用程序的初始化方式。 在下一节中了解更多信息。","link":"/p/87290a79.html"}],"tags":[{"name":"angular","slug":"angular","link":"/tags/angular/"},{"name":"前端","slug":"前端","link":"/tags/%E5%89%8D%E7%AB%AF/"},{"name":"JavaScript","slug":"JavaScript","link":"/tags/JavaScript/"},{"name":"Dubbo","slug":"Dubbo","link":"/tags/Dubbo/"},{"name":"java","slug":"java","link":"/tags/java/"},{"name":"etcd","slug":"etcd","link":"/tags/etcd/"},{"name":"Java","slug":"Java","link":"/tags/Java/"},{"name":"Spring","slug":"Spring","link":"/tags/Spring/"},{"name":"git","slug":"git","link":"/tags/git/"},{"name":"hexo","slug":"hexo","link":"/tags/hexo/"},{"name":"Nginx","slug":"Nginx","link":"/tags/Nginx/"},{"name":"Linux","slug":"Linux","link":"/tags/Linux/"},{"name":"Scala","slug":"Scala","link":"/tags/Scala/"},{"name":"Play","slug":"Play","link":"/tags/Play/"},{"name":"rocketmq","slug":"rocketmq","link":"/tags/rocketmq/"},{"name":"spring","slug":"spring","link":"/tags/spring/"},{"name":"Docker","slug":"Docker","link":"/tags/Docker/"},{"name":"Zookeeper","slug":"Zookeeper","link":"/tags/Zookeeper/"}],"categories":[{"name":"前端","slug":"前端","link":"/categories/%E5%89%8D%E7%AB%AF/"},{"name":"Dubbo","slug":"Dubbo","link":"/categories/Dubbo/"},{"name":"java","slug":"java","link":"/categories/java/"},{"name":"angular","slug":"前端/angular","link":"/categories/%E5%89%8D%E7%AB%AF/angular/"},{"name":"Java","slug":"Java","link":"/categories/Java/"},{"name":"hexo","slug":"hexo","link":"/categories/hexo/"},{"name":"JavaScript","slug":"前端/JavaScript","link":"/categories/%E5%89%8D%E7%AB%AF/JavaScript/"},{"name":"Nginx","slug":"Nginx","link":"/categories/Nginx/"},{"name":"Play","slug":"Play","link":"/categories/Play/"},{"name":"Scala","slug":"Scala","link":"/categories/Scala/"},{"name":"rocketmq","slug":"java/rocketmq","link":"/categories/java/rocketmq/"},{"name":"Linux","slug":"Nginx/Linux","link":"/categories/Nginx/Linux/"},{"name":"Spring","slug":"Java/Spring","link":"/categories/Java/Spring/"},{"name":"spring专题","slug":"java/spring专题","link":"/categories/java/spring%E4%B8%93%E9%A2%98/"},{"name":"Docker","slug":"Docker","link":"/categories/Docker/"}]}